{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4fc27c-e8b7-4bf5-9c8d-75024f3ef3eb",
   "metadata": {},
   "source": [
    "# Late Fusion Model based on HAIM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f24a44-f617-409a-8d5d-6eed11bf8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant code chunks to adapt to our purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0a2472f-e9e3-47f5-9d47-6b21e6de5e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports adapted from HAIM API.py\n",
    "# Base\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import datetime as dt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "from dask import dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "ProgressBar().register()\n",
    "\n",
    "# Core AI/ML\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision, torchvision.transforms #causing problems\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Scipy\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "\n",
    "# NLP\n",
    "from transformers import AutoTokenizer, AutoModel, logging\n",
    "logging.set_verbosity_error()\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "biobert_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Computer Vision\n",
    "import cv2\n",
    "import skimage, skimage.io\n",
    "import torchxrayvision as xrv\n",
    "import timm\n",
    "\n",
    "# Warning handling\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5166ed5-e1ad-46b4-a405-b893c331ed7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to for each individual model - save the model to run on images\n",
    "#or save the final output layers (better, more consistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6e28cd8-8c23-45fa-8369-d154a4f1efbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images embeddings\n",
    "def get_single_chest_xray_embeddings(img, model=\"HAIM\"):\n",
    "    # Inputs:\n",
    "    #   img -> Image array\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   densefeature_embeddings ->  CXR dense feature embeddings for image\n",
    "    #   prediction_embeddings ->  CXR embeddings of predictions for image\n",
    "    \n",
    "    \n",
    "    # %% EXAMPLE OF USE\n",
    "    # densefeature_embeddings, prediction_embeddings = get_single_chest_xray_embeddings(img)\n",
    "    \n",
    "    # Clean out process bar before starting\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    # Select if you want to use CUDA support for GPU (optional as it is usually pretty fast even in CPUT)\n",
    "    cuda = False\n",
    "    \n",
    "    # Select model with a String that determines the model to use for Chest Xrays according to https://github.com/mlmed/torchxrayvision\n",
    "    #model_weights_name = \"densenet121-res224-all\" # Every output trained for all models\n",
    "    #model_weights_name = \"densenet121-res224-rsna\" # RSNA Pneumonia Challenge\n",
    "    #model_weights_name = \"densenet121-res224-nih\" # NIH chest X-ray8\n",
    "    #model_weights_name = \"densenet121-res224-pc\") # PadChest (University of Alicante)\n",
    "    if model == \"HAIM\":\n",
    "        model_weights_name = \"densenet121-res224-chex\" # CheXpert (Stanford)\n",
    "    elif model == \"EffNet\":\n",
    "        pass\n",
    "    else:\n",
    "        model_weights_name = \"densenet121-res224-chex\" # replace with our model when we can    #model_weights_name = \"densenet121-res224-mimic_nb\" # MIMIC-CXR (MIT)\n",
    "    #model_weights_name = \"densenet121-res224-mimic_ch\" # MIMIC-CXR (MIT)\n",
    "    #model_weights_name = \"resnet50-res512-all\" # Resnet only for 512x512 inputs\n",
    "    # NOTE: The all model has every output trained. However, for the other weights some targets are not trained and will predict randomly becuase they do not exist in the training dataset.\n",
    "    \n",
    "    # Extract chest x-ray image embeddings and preddictions\n",
    "    densefeature_embeddings = []\n",
    "    prediction_embeddings = []\n",
    "    \n",
    "    #img = skimage.io.imread(img_path) # If importing from path use this\n",
    "    img = xrv.datasets.normalize(img, 255)\n",
    "\n",
    "    # For each image check if they are 2D arrays\n",
    "    if len(img.shape) > 2:\n",
    "        img = img[:, :, 0]\n",
    "    if len(img.shape) < 2:\n",
    "        print(\"Error: Dimension lower than 2 for image!\")\n",
    "    \n",
    "    # Add color channel for prediction\n",
    "    #Resize using OpenCV\n",
    "    img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)   \n",
    "    img = img[None, :, :]\n",
    "\n",
    "    #Or resize using core resizer (thows error sometime)\n",
    "    #transform = transforms.Compose([xrv.datasets.XRayCenterCrop(),xrv.datasets.XRayResizer(224)])\n",
    "    #img = transform(img)\n",
    "    if model == \"HAIM\":\n",
    "        model = xrv.models.DenseNet(weights = model_weights_name)\n",
    "    elif model == \"MMMM\":\n",
    "        model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=5)\n",
    "    else:\n",
    "        model = xrv.models.DenseNet(weights = model_weights_name)    # model = xrv.models.ResNet(weights=\"resnet50-res512-all\") # ResNet is also available\n",
    "\n",
    "    output = {}\n",
    "    with torch.no_grad():\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        if cuda:\n",
    "            img = img.cuda()\n",
    "            model = model.cuda()\n",
    "          \n",
    "        # Extract dense features\n",
    "        feats = model.features(img)\n",
    "        feats = F.relu(feats, inplace=True)\n",
    "        feats = F.adaptive_avg_pool2d(feats, (1, 1))\n",
    "        densefeatures = feats.cpu().detach().numpy().reshape(-1)\n",
    "        densefeature_embeddings = densefeatures\n",
    "\n",
    "        # Extract predicted probabilities of considered 18 classes:\n",
    "        # Get by calling \"xrv.datasets.default_pathologies\" or \"dict(zip(xrv.datasets.default_pathologies,preds[0].detach().numpy()))\"\n",
    "        # ['Atelectasis','Consolidation','Infiltration','Pneumothorax','Edema','Emphysema',Fibrosis',\n",
    "        #  'Effusion','Pneumonia','Pleural_Thickening','Cardiomegaly','Nodule',Mass','Hernia',\n",
    "        #  'Lung Lesion','Fracture','Lung Opacity','Enlarged Cardiomediastinum']\n",
    "        preds = model(img).cpu()\n",
    "        predictions = preds[0].detach().numpy()\n",
    "        prediction_embeddings = predictions  \n",
    "\n",
    "    # Return embeddings\n",
    "    return densefeature_embeddings, prediction_embeddings\n",
    "\n",
    "def get_chest_xray_embeddings(dt_patient, model=\"HAIM\", verbose=0):\n",
    "    # Inputs:\n",
    "    #   dt_patient -> Timebound ICU patient stay structure filtered by max_time_stamp or min_time_stamp if any\n",
    "    #   verbose -> Level of printed output of function\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   aggregated_densefeature_embeddings -> CXR aggregated dense feature embeddings for all images in timebound patient\n",
    "    #   densefeature_embeddings ->  List of CXR dense feature embeddings for all images\n",
    "    #   aggregated_prediction_embeddings -> CXR aggregated embeddings of predictions for all images in timebound patient\n",
    "    #   prediction_embeddings ->  List of CXR embeddings of predictions for all images\n",
    "    #   imgs_weights ->  Array of weights for embedding aggregation\n",
    "\n",
    "\n",
    "    # %% EXAMPLE OF USE\n",
    "    # aggregated_densefeature_embeddings, densefeature_embeddings, aggregated_prediction_embeddings, prediction_embeddings, imgs_weights = get_chest_xray_embeddings(dt_patient, verbose=2)\n",
    "\n",
    "    # Clean out process bar before starting\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Select if you want to use CUDA support for GPU (optional as it is usually pretty fast even in CPUT)\n",
    "    cuda = False\n",
    "\n",
    "    # Select model with a String that determines the model to use for Chest Xrays according to https://github.com/mlmed/torchxrayvision\n",
    "    #   model_weights_name = \"densenet121-res224-all\" # Every output trained for all models\n",
    "    #   model_weights_name = \"densenet121-res224-rsna\" # RSNA Pneumonia Challenge\n",
    "    #model_weights_name = \"densenet121-res224-nih\" # NIH chest X-ray8\n",
    "    #model_weights_name = \"densenet121-res224-pc\") # PadChest (University of Alicante)\n",
    "    if model == \"HAIM\":\n",
    "        model_weights_name = \"densenet121-res224-chex\" # CheXpert (Stanford)\n",
    "    elif model == \"EffNet\":\n",
    "        pass\n",
    "    else:\n",
    "        model_weights_name = \"densenet121-res224-chex\" # replace with our model when we can\n",
    "        \n",
    "    #   model_weights_name = \"densenet121-res224-mimic_nb\" # MIMIC-CXR (MIT)\n",
    "    #model_weights_name = \"densenet121-res224-mimic_ch\") # MIMIC-CXR (MIT)\n",
    "    #model_weights_name = \"resnet50-res512-all\" # Resnet only for 512x512 inputs\n",
    "    # NOTE: The all model has every output trained. However, for the other weights some targets are not trained and will predict randomly becuase they do not exist in the training dataset.\n",
    "\n",
    "\n",
    "    # Extract chest x-ray images from timebound patient and iterate through them\n",
    "    imgs = dt_patient.imcxr\n",
    "    densefeature_embeddings = []\n",
    "    prediction_embeddings = []\n",
    "\n",
    "    # Iterate\n",
    "    nImgs = len(imgs)\n",
    "    with tqdm(total = nImgs) as pbar:\n",
    "        for idx, img in enumerate(imgs):\n",
    "            #img = skimage.io.imread(img_path) # If importing from path use this\n",
    "            img = xrv.datasets.normalize(img, 255)\n",
    "          \n",
    "            # For each image check if they are 2D arrays\n",
    "            if len(img.shape) > 2:\n",
    "                img = img[:, :, 0]\n",
    "            if len(img.shape) < 2:\n",
    "                print(\"Error: Dimension lower than 2 for image!\")\n",
    "\n",
    "            # Add color channel for prediction\n",
    "            #Resize using OpenCV\n",
    "            img = cv2.resize(img, (224, 224), interpolation = cv2.INTER_AREA)   \n",
    "            img = img[None, :, :]\n",
    "            \n",
    "            #Or resize using core resizer (thows error sometime)\n",
    "            #transform = transforms.Compose([xrv.datasets.XRayCenterCrop(),xrv.datasets.XRayResizer(224)])\n",
    "            #img = transform(img)\n",
    "            if model == \"HAIM\":\n",
    "                model = xrv.models.DenseNet(weights = model_weights_name)\n",
    "            elif model == \"MMMM\":\n",
    "                model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=5)\n",
    "            else:\n",
    "                model = xrv.models.DenseNet(weights = model_weights_name)\n",
    "            # model = xrv.models.ResNet(weights=\"resnet50-res512-all\") # ResNet is also available\n",
    "            \n",
    "            output = {}\n",
    "            with torch.no_grad():\n",
    "                img = torch.from_numpy(img).unsqueeze(0)\n",
    "                if cuda:\n",
    "                    img = img.cuda()\n",
    "                    model = model.cuda()\n",
    "              \n",
    "                # Extract dense features\n",
    "                feats = model.features(img)\n",
    "                feats = F.relu(feats, inplace=True)\n",
    "                feats = F.adaptive_avg_pool2d(feats, (1, 1))\n",
    "                densefeatures = feats.cpu().detach().numpy().reshape(-1)\n",
    "                densefeature_embeddings.append(densefeatures) # append to list of dense features for all images\n",
    "                \n",
    "                # Extract predicted probabilities of considered 18 classes:\n",
    "                # Get by calling \"xrv.datasets.default_pathologies\" or \"dict(zip(xrv.datasets.default_pathologies,preds[0].detach().numpy()))\"\n",
    "                # ['Atelectasis','Consolidation','Infiltration','Pneumothorax','Edema','Emphysema',Fibrosis',\n",
    "                #  'Effusion','Pneumonia','Pleural_Thickening','Cardiomegaly','Nodule',Mass','Hernia',\n",
    "                #  'Lung Lesion','Fracture','Lung Opacity','Enlarged Cardiomediastinum']\n",
    "                preds = model(img).cpu()\n",
    "                predictions = preds[0].detach().numpy()\n",
    "                prediction_embeddings.append(predictions) # append to list of predictions for all images\n",
    "            \n",
    "                if verbose >=1:\n",
    "                    # Update process bar\n",
    "                    pbar.update(1)\n",
    "        \n",
    "        \n",
    "    # Get image weights by hours passed from current time to image\n",
    "    orig_imgs_weights = np.asarray(dt_patient.cxr.deltacharttime.values)\n",
    "    adj_imgs_weights = orig_imgs_weights - orig_imgs_weights.min()\n",
    "    imgs_weights = (adj_imgs_weights) / (adj_imgs_weights).max()\n",
    "  \n",
    "    # Aggregate with weighted average of ebedding vector across temporal dimension\n",
    "    try:\n",
    "        aggregated_densefeature_embeddings = np.average(densefeature_embeddings, axis=0, weights=imgs_weights)\n",
    "        if np.isnan(np.sum(aggregated_densefeature_embeddings)):\n",
    "            aggregated_densefeature_embeddings = np.zeros_like(densefeature_embeddings[0])\n",
    "    except:\n",
    "        aggregated_densefeature_embeddings = np.zeros_like(densefeature_embeddings[0])\n",
    "      \n",
    "    try:\n",
    "        aggregated_prediction_embeddings = np.average(prediction_embeddings, axis=0, weights=imgs_weights)\n",
    "        if np.isnan(np.sum(aggregated_prediction_embeddings)):\n",
    "            aggregated_prediction_embeddings = np.zeros_like(prediction_embeddings[0])\n",
    "    except:\n",
    "        aggregated_prediction_embeddings = np.zeros_like(prediction_embeddings[0])\n",
    "      \n",
    "      \n",
    "    if verbose >=2:\n",
    "        x = orig_imgs_weights\n",
    "        y = prediction_embeddings\n",
    "        plt.xlabel(\"Time [hrs]\")\n",
    "        plt.ylabel(\"Disease probability [0-1]\")\n",
    "        plt.title(\"A test graph\")\n",
    "        for i in range(len(y[0])):\n",
    "            plt.plot(x,[pt[i] for pt in y],'o', label = xrv.datasets.default_pathologies[i])\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "        plt.show()\n",
    "\n",
    "    # Return embeddings\n",
    "    return aggregated_densefeature_embeddings, densefeature_embeddings, aggregated_prediction_embeddings, prediction_embeddings, imgs_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23f07a6c-0b30-4542-8e22-0668967471da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes embeddings\n",
    "#main function\n",
    "def get_biobert_embeddings(text):\n",
    "    # Inputs:\n",
    "    #   text -> Input text (str)\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   embeddings -> Final Biobert embeddings with vector dimensionality = (1,768)\n",
    "    #   hidden_embeddings -> Last hidden layer in Biobert model with vector dimensionality = (token_size,768)\n",
    "  \n",
    "    # %% EXAMPLE OF USE\n",
    "    # embeddings, hidden_embeddings = get_biobert_embeddings(text)\n",
    "  \n",
    "    tokens_pt = biobert_tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = biobert_model(**tokens_pt)\n",
    "    last_hidden_state = outputs.last_hidden_state\n",
    "    pooler_output = outputs.pooler_output\n",
    "    hidden_embeddings = last_hidden_state.detach().numpy()\n",
    "    embeddings = pooler_output.detach().numpy()\n",
    "\n",
    "    return embeddings, hidden_embeddings\n",
    "\n",
    "#alternative functions\n",
    "def get_biobert_embedding_from_events_list(full_events_list, event_weights, verbose = 0):\n",
    "    # Inputs:\n",
    "    #   full_events_list -> Timebound ICU patient stay structure filtered by max_time_stamp or min_time_stamp if any\n",
    "    #   event_weights ->  Weights for aggregation of features in final embeddings\n",
    "    #   verbose -> Level of printed output of function\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   aggregated_embeddings -> Biobert event features for all events\n",
    "    #   full_embeddings -> Biobert event features across each event line\n",
    "    #   event_weights -> Finally used weights for aggregation of features in final embeddings\n",
    "  \n",
    "    # %% EXAMPLE OF USE\n",
    "    # aggregated_embeddings, full_embeddings, event_weights = get_biobert_embedding_from_events_list(full_events_list, event_weights, verbose=1)\n",
    "  \n",
    "    event_weights_exp = []\n",
    "    for idx, event_string in enumerate(full_events_list):   \n",
    "        weight = event_weights.values[idx]\n",
    "        string_list, lengths = split_note_document(event_string)\n",
    "        for idx_sub, event_string_sub in enumerate(string_list):\n",
    "            #Extract biobert embedding\n",
    "            embedding, hidden_embedding = get_biobert_embeddings(event_string_sub)\n",
    "            #Concatenate\n",
    "            if (idx==0) & (idx_sub==0):\n",
    "                full_embedding = embedding\n",
    "            else: \n",
    "                full_embedding = np.concatenate((full_embedding, embedding), axis=0)\n",
    "            event_weights_exp.append(weight)\n",
    "          \n",
    "    # Return the weighted average of ebedding vector across temporal dimension\n",
    "    try:\n",
    "        #aggregated_embedding = np.dot(np.transpose(full_embedding), np.array(event_weights_exp))\n",
    "        aggregated_embedding = np.average(full_embedding, axis=0, weights=np.array(event_weights_exp))\n",
    "    except:\n",
    "        aggregated_embedding = np.zeros(768)\n",
    "      \n",
    "    return aggregated_embedding, full_embedding, event_weights\n",
    "\n",
    "def get_notes_biobert_embeddings(dt_patient, note_type):\n",
    "    # Inputs:\n",
    "    #   dt_patient -> Timebound ICU patient stay structure filtered by max_time_stamp or min_time_stamp if any\n",
    "    #   note_type -> Type of note to get\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   aggregated_embeddings -> Biobert event features for selected note\n",
    "  \n",
    "    # %% EXAMPLE OF USE\n",
    "    # aggregated_embeddings = get_notes_biobert_embeddings(dt_patient, note_type = 'ecgnotes')\n",
    "  \n",
    "    admittime = dt_patient.core['admittime'].values[0]\n",
    "    note_table = getattr(dt_patient, note_type).copy()\n",
    "    note_table['deltacharttime'] = note_table['charttime'].apply(lambda x: (x.replace(tzinfo=None) - admittime).total_seconds()/3600)\n",
    "    try:\n",
    "        aggregated_embeddings, __, __ = get_biobert_embedding_from_events_list(note_table['text'], note_table['deltacharttime'])\n",
    "    except:\n",
    "        aggregated_embeddings, __, __ = get_biobert_embedding_from_events_list(pd.Series([\"\"]), pd.Series([1]))\n",
    "  \n",
    "    return aggregated_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8eb0064-eea3-4866-9c7a-1d18a4cd52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabular embeddings\n",
    "#need to build our own models for these\n",
    "#for now, append tabular data similarly to demographic data (as raw values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbbaf616-68e1-4571-925d-6e7f09117570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAIM's concatentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f6a3408-e9c5-4651-a3ea-f8af8a73d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "##test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d552ab69-523c-4482-86ac-d0a88dbd2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files... C:/Users/Carolyn/Documents/MIDS/210 Capstone/fusion_data\\test_set__chexpert__4_findings__single_label__unbalanced.json test\n",
      "Loading data files... C:/Users/Carolyn/Documents/MIDS/210 Capstone/fusion_data\\train_set__chexpert__4_findings__single_label__unbalanced.json train\n",
      "Loading data files... C:/Users/Carolyn/Documents/MIDS/210 Capstone/fusion_data\\validation_set__chexpert__4_findings__single_label__unbalanced.json validate\n",
      "Total Cols\n",
      " Index(['patient_id', 'visit_id', 'study_id', 'temperature', 'heartrate',\n",
      "       'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity',\n",
      "       'positive_label_total', 'finding_names', 'radiology_note',\n",
      "       'discharge_note', 'chief_complaint',\n",
      "       'major_surgical_or_invasive_procedure', 'history_of_present_illness',\n",
      "       'past_medical_history', 'family_history', 'atelectasis', 'cardiomegaly',\n",
      "       'lung_opacity', 'pleural_effusion', 'dataset_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#loads data into memory (from local files for now)\n",
    "%run processing_data.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47ba3408-d9d2-4684-9d2a-9528a4998e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pain</th>\n",
       "      <th>acuity</th>\n",
       "      <th>positive_label_total</th>\n",
       "      <th>finding_names</th>\n",
       "      <th>radiology_note</th>\n",
       "      <th>discharge_note</th>\n",
       "      <th>chief_complaint</th>\n",
       "      <th>major_surgical_or_invasive_procedure</th>\n",
       "      <th>history_of_present_illness</th>\n",
       "      <th>past_medical_history</th>\n",
       "      <th>family_history</th>\n",
       "      <th>atelectasis</th>\n",
       "      <th>cardiomegaly</th>\n",
       "      <th>lung_opacity</th>\n",
       "      <th>pleural_effusion</th>\n",
       "      <th>dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000935.0</td>\n",
       "      <td>26381316</td>\n",
       "      <td>51178377.0</td>\n",
       "      <td>97.6</td>\n",
       "      <td>117.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lung_opacity</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>Weakness, nausea/vomiting</td>\n",
       "      <td>none</td>\n",
       "      <td>This is a ___ yo f with h/o recently diagnosed...</td>\n",
       "      <td>PMH: \\n# high grade SBO ___ s/p exploratory la...</td>\n",
       "      <td>Mother - ___ cancer d. at ___  \\nYoungest of _...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000980.0</td>\n",
       "      <td>29654838</td>\n",
       "      <td>59988438.0</td>\n",
       "      <td>97.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pleural_effusion</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>Shortness of breath</td>\n",
       "      <td>None</td>\n",
       "      <td>___ yo woman with h/o hypertension, hyperlipid...</td>\n",
       "      <td>1. CAD RISK FACTORS: +Diabetes, +Dyslipidemia,...</td>\n",
       "      <td>Denies cardiac family history. Family hx of DM...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001176.0</td>\n",
       "      <td>23334588</td>\n",
       "      <td>53186264.0</td>\n",
       "      <td>101.3</td>\n",
       "      <td>97.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lung_opacity</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>fever</td>\n",
       "      <td>none</td>\n",
       "      <td>___ with history of morbid obesity, coronary a...</td>\n",
       "      <td>MYOCARDIAL INFARCT - INFEROPOSTERIOR  \\nHYPERC...</td>\n",
       "      <td>Non contributory</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001217.0</td>\n",
       "      <td>24597018</td>\n",
       "      <td>52067803.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___              Unit No:   ___\\n \\n...</td>\n",
       "      <td>Left hand and face numbness, left hand weaknes...</td>\n",
       "      <td>Right parietal craniotomy for abscess incision...</td>\n",
       "      <td>Mrs. ___ is a ___ y/o F from ___ with history ...</td>\n",
       "      <td>Multiple sclerosis</td>\n",
       "      <td>Mother with pancreatic cancer, brother-lung ca...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001401.0</td>\n",
       "      <td>26840593</td>\n",
       "      <td>51065211.0</td>\n",
       "      <td>97.8</td>\n",
       "      <td>67.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___              Unit No:   ___\\n \\n...</td>\n",
       "      <td>Abdominal pain, distention, nausea</td>\n",
       "      <td>Interventional radiology placement of abdomina...</td>\n",
       "      <td>___ F with h/o muscle invasive bladder cancer,...</td>\n",
       "      <td>Hypertension, laparoscopic cholecystectomy, le...</td>\n",
       "      <td>Negative for bladder CA.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  visit_id    study_id  temperature  heartrate  resprate  o2sat  \\\n",
       "0  10000935.0  26381316  51178377.0         97.6      117.0      18.0   95.0   \n",
       "1  10000980.0  29654838  59988438.0         97.8       57.0      18.0  100.0   \n",
       "2  10001176.0  23334588  53186264.0        101.3       97.0      18.0   93.0   \n",
       "3  10001217.0  24597018  52067803.0         99.0       81.0      16.0   97.0   \n",
       "4  10001401.0  26840593  51065211.0         97.8       67.0      20.0   95.0   \n",
       "\n",
       "     sbp    dbp  pain  acuity  positive_label_total     finding_names  \\\n",
       "0  128.0   74.0    10     3.0                   1.0      lung_opacity   \n",
       "1  180.0   88.0     0     2.0                   1.0  pleural_effusion   \n",
       "2  168.0   58.0     6     3.0                   1.0      lung_opacity   \n",
       "3  160.0  102.0     0     3.0                   1.0       atelectasis   \n",
       "4   90.0   43.0     8     2.0                   1.0       atelectasis   \n",
       "\n",
       "                                      radiology_note  \\\n",
       "0                                   FINAL REPORT\\...   \n",
       "1                                   FINAL REPORT\\...   \n",
       "2                                   FINAL REPORT\\...   \n",
       "3                                   FINAL REPORT\\...   \n",
       "4                                   FINAL REPORT\\...   \n",
       "\n",
       "                                      discharge_note  \\\n",
       "0   \\nName:  ___                   Unit No:   ___...   \n",
       "1   \\nName:  ___          Unit No:   ___\\n \\nAdmi...   \n",
       "2   \\nName:  ___                   Unit No:   ___...   \n",
       "3   \\nName:  ___              Unit No:   ___\\n \\n...   \n",
       "4   \\nName:  ___              Unit No:   ___\\n \\n...   \n",
       "\n",
       "                                     chief_complaint  \\\n",
       "0                          Weakness, nausea/vomiting   \n",
       "1                                Shortness of breath   \n",
       "2                                              fever   \n",
       "3  Left hand and face numbness, left hand weaknes...   \n",
       "4                 Abdominal pain, distention, nausea   \n",
       "\n",
       "                major_surgical_or_invasive_procedure  \\\n",
       "0                                               none   \n",
       "1                                               None   \n",
       "2                                               none   \n",
       "3  Right parietal craniotomy for abscess incision...   \n",
       "4  Interventional radiology placement of abdomina...   \n",
       "\n",
       "                          history_of_present_illness  \\\n",
       "0  This is a ___ yo f with h/o recently diagnosed...   \n",
       "1  ___ yo woman with h/o hypertension, hyperlipid...   \n",
       "2  ___ with history of morbid obesity, coronary a...   \n",
       "3  Mrs. ___ is a ___ y/o F from ___ with history ...   \n",
       "4  ___ F with h/o muscle invasive bladder cancer,...   \n",
       "\n",
       "                                past_medical_history  \\\n",
       "0  PMH: \\n# high grade SBO ___ s/p exploratory la...   \n",
       "1  1. CAD RISK FACTORS: +Diabetes, +Dyslipidemia,...   \n",
       "2  MYOCARDIAL INFARCT - INFEROPOSTERIOR  \\nHYPERC...   \n",
       "3                                 Multiple sclerosis   \n",
       "4  Hypertension, laparoscopic cholecystectomy, le...   \n",
       "\n",
       "                                      family_history  atelectasis  \\\n",
       "0  Mother - ___ cancer d. at ___  \\nYoungest of _...          0.0   \n",
       "1  Denies cardiac family history. Family hx of DM...          0.0   \n",
       "2                                   Non contributory          0.0   \n",
       "3  Mother with pancreatic cancer, brother-lung ca...          1.0   \n",
       "4                           Negative for bladder CA.          1.0   \n",
       "\n",
       "   cardiomegaly  lung_opacity  pleural_effusion dataset_type  \n",
       "0           0.0           1.0               0.0        train  \n",
       "1           0.0           0.0               1.0        train  \n",
       "2           0.0           1.0               0.0        train  \n",
       "3           0.0           0.0               0.0        train  \n",
       "4           0.0           0.0               0.0        train  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6db426b6-9e53-410a-ab4b-f0f25b235600",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings, test_hidden_embeddings = get_biobert_embeddings(train_df['history_of_present_illness'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4992b637-6747-4145-8752-d4e5220f6a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c7f65ed-6bc3-4bb5-ae9f-6f2280f4ff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 221, 768)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_hidden_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f4a999-e849-4ce1-adcd-f8a452f0eb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

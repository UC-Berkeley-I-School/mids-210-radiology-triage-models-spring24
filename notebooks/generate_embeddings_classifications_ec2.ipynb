{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4fc27c-e8b7-4bf5-9c8d-75024f3ef3eb",
   "metadata": {},
   "source": [
    "# Late Fusion Model Embeddings Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff28a5-34a2-43d1-a346-8d287585e8f6",
   "metadata": {},
   "source": [
    "Purpose of this notebook: Generate embeddings for Late Fusion Model\n",
    "\n",
    "Based on paper: Soenksen, L.R., Ma, Y., Zeng, C. et al. Integrated multimodal artificial intelligence framework for healthcare applications. npj Digit. Med. 5, 149 (2022). https://doi.org/10.1038/s41746-022-00689-4\n",
    "\n",
    "Using our best tabular, notes, and imaging models, getting the embeddings and classifications for additional modelling\n",
    "\n",
    "Goal: model using embeddings alone, or embeddings + classification (approach done in Soenksen et al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f24a44-f617-409a-8d5d-6eed11bf8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#relevant code chunks to adapt to our purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89008c47-674c-41a4-8967-d0b7416a3f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports adapted from HAIM API.py\n",
    "# Base\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas.io.sql as psql\n",
    "import datetime as dt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from shutil import copyfile\n",
    "\n",
    "# Core AI/ML\n",
    "#import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision, torchvision.transforms #causing problems\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchinfo import summary\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "\n",
    "# NLP\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel, logging\n",
    "logging.set_verbosity_error()\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Computer Vision\n",
    "import timm\n",
    "from PIL import Image\n",
    "\n",
    "# Warning handling\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24db65bb-c000-4ba0-bdbb-2045734eb63d",
   "metadata": {},
   "source": [
    "# Data Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa367fb9-3400-4939-b395-92e362083079",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variables_dict = {\n",
    "    'no_finding': 0,\n",
    "    'atelectasis': 1,\n",
    "    'cardiomegaly': 2,\n",
    "    'lung_opacity': 3,\n",
    "    'pleural_effusion': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b58121-cb38-40eb-9eb4-31852341d769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files... ../data/s3/fusion_data/test_set__chexpert__4_findings__single_label__unbalanced.json test\n",
      "Loading data files... ../data/s3/fusion_data/train_set__chexpert__4_findings__single_label__balanced.json train\n",
      "Loading data files... ../data/s3/fusion_data/validation_set__chexpert__4_findings__single_label__unbalanced.json validate\n",
      "Total Cols\n",
      " Index(['patient_id', 'visit_id', 'study_id', 'temperature', 'heartrate',\n",
      "       'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity',\n",
      "       'positive_label_total', 'finding_names', 'radiology_note',\n",
      "       'discharge_note', 'chief_complaint',\n",
      "       'major_surgical_or_invasive_procedure', 'history_of_present_illness',\n",
      "       'past_medical_history', 'family_history', 'atelectasis', 'cardiomegaly',\n",
      "       'lung_opacity', 'pleural_effusion', 'dataset_type'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16877 entries, 0 to 16876\n",
      "Data columns (total 40 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   patient_id                                  16877 non-null  int64  \n",
      " 1   study_id                                    16877 non-null  int64  \n",
      " 2   atelectasis                                 16877 non-null  float64\n",
      " 3   cardiomegaly                                16877 non-null  float64\n",
      " 4   edema                                       16877 non-null  float64\n",
      " 5   lung_opacity                                16877 non-null  float64\n",
      " 6   pleural_effusion                            16877 non-null  float64\n",
      " 7   pneumonia                                   16877 non-null  float64\n",
      " 8   prev_data_type                              16877 non-null  object \n",
      " 9   prev_is_sample                              16877 non-null  bool   \n",
      " 10  dicom_id                                    16877 non-null  object \n",
      " 11  PerformedProcedureStepDescription           16817 non-null  object \n",
      " 12  ViewPosition                                16877 non-null  object \n",
      " 13  Rows                                        16877 non-null  int64  \n",
      " 14  Columns                                     16877 non-null  int64  \n",
      " 15  StudyDate                                   16877 non-null  int64  \n",
      " 16  StudyTime                                   16877 non-null  float64\n",
      " 17  ProcedureCodeSequence_CodeMeaning           16877 non-null  object \n",
      " 18  ViewCodeSequence_CodeMeaning                16877 non-null  object \n",
      " 19  PatientOrientationCodeSequence_CodeMeaning  16520 non-null  object \n",
      " 20  jpg_filename                                16877 non-null  object \n",
      " 21  anomaly                                     16877 non-null  int64  \n",
      " 22  no_findings                                 16877 non-null  bool   \n",
      " 23  set                                         16877 non-null  int64  \n",
      " 24  train_6_unb_m                               16877 non-null  int64  \n",
      " 25  test_6_unb_m                                16877 non-null  int64  \n",
      " 26  val_6_unb_m                                 16877 non-null  int64  \n",
      " 27  train_6_bal_m                               16877 non-null  int64  \n",
      " 28  train_6_unb_s                               16877 non-null  int64  \n",
      " 29  test_6_unb_s                                16877 non-null  int64  \n",
      " 30  val_6_unb_s                                 16877 non-null  int64  \n",
      " 31  train_6_bal_s                               16877 non-null  int64  \n",
      " 32  train_4_unb_m                               16877 non-null  int64  \n",
      " 33  test_4_unb_m                                16877 non-null  int64  \n",
      " 34  val_4_unb_m                                 16877 non-null  int64  \n",
      " 35  train_4_bal_m                               16877 non-null  int64  \n",
      " 36  train_4_unb_s                               16877 non-null  int64  \n",
      " 37  test_4_unb_s                                16877 non-null  int64  \n",
      " 38  val_4_unb_s                                 16877 non-null  int64  \n",
      " 39  train_4_bal_s                               16877 non-null  int64  \n",
      "dtypes: bool(2), float64(7), int64(23), object(8)\n",
      "memory usage: 4.9+ MB\n",
      "\n",
      "\n",
      "Create combined train, validation, and test datasets from note/tabular and imaging data of sizes: \n",
      "(2086, 27)\n",
      "(1924, 27)\n",
      "(1920, 27)\n",
      "Null values for image IDs in combined_train_df: 0\n",
      "Null values for image IDs in combined_train_df: 0\n",
      "Null values for image IDs in combined_train_df: 0\n",
      "\n",
      "\n",
      "Combined dataset has columns: Index(['index', 'patient_id', 'visit_id', 'study_id', 'temperature',\n",
      "       'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity',\n",
      "       'positive_label_total', 'finding_names', 'radiology_note',\n",
      "       'discharge_note', 'chief_complaint',\n",
      "       'major_surgical_or_invasive_procedure', 'history_of_present_illness',\n",
      "       'past_medical_history', 'family_history', 'atelectasis', 'cardiomegaly',\n",
      "       'lung_opacity', 'pleural_effusion', 'dataset_type', 'dicom_id'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Combined dataset has the following findings (true labels): ['atelectasis' 'cardiomegaly' 'lung_opacity' 'pleural_effusion'\n",
      " 'no_finding']\n",
      "\n",
      "\n",
      "Split combined data into images, notes, and tabular datasets\n",
      "Imaging data has columns Index(['patient_id', 'dicom_id', 'finding_names'], dtype='object')\n",
      "Notes data has columns Index(['patient_id', 'chief_complaint', 'history_of_present_illness',\n",
      "       'past_medical_history', 'family_history', 'finding_names'],\n",
      "      dtype='object')\n",
      "Tabular data has columns Index(['patient_id', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
      "       'dbp', 'pain', 'acuity', 'finding_names'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      "Processed all notes data to have [UNK] in place of ____\n",
      "\n",
      "\n",
      "Created file img_train_df with size: (2086, 3)\n",
      "Created file img_val_df with size: (1924, 3)\n",
      "Created file img_test_df with size: (1920, 3)\n",
      "Created file notes_train_df with size: (2086, 6)\n",
      "Created file notes_val_df with size: (1924, 6)\n",
      "Created file notes_test_df with size: (1920, 6)\n",
      "Created file tabular_train_df with size: (2086, 10)\n",
      "Created file tabular_val_df with size: (1924, 10)\n",
      "Created file tabular_test_df with size: (1920, 10)\n"
     ]
    }
   ],
   "source": [
    "#run processing notebook to get data files\n",
    "%run processing_data_ec2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eca75f-5181-43f4-84f3-c1e8f0db9bc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7596452e-7801-4195-919a-9e1d7e32fa69",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Notes Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5263ac2a-5464-4449-8b83-17604b1823ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original biobert models\n",
    "biobert_tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "biobert_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4847147a-3d28-45e5-9a4d-1c90501456e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the Bio_Discharge_Summary_BERT model\n",
    "MODEL_CHECKPOINT = 'emilyalsentzer/Bio_ClinicalBERT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5c6047a-55ee-47b8-a341-cd25c62acc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select parameters\n",
    "NUM_CLASSES = 5\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "NUM_EPOCHS = 15\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb93943a-9d69-4e8d-8572-f6630f9f8d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassClassification(nn.Module):\n",
    "\n",
    "    def __init__(self, checkpoint, num_classes, hidden_size=201, dropout_prob=0.3, freeze_bert=True):\n",
    "        super(MulticlassClassification, self).__init__()\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(checkpoint)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        self.num_classes = num_classes\n",
    "        self.freeze_bert = freeze_bert\n",
    "\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = not self.freeze_bert\n",
    "\n",
    "        self.pooler_layer = nn.Linear(self.model.config.hidden_size, hidden_size) # maps the output of the BERT model's hidden state to the hidden_size\n",
    "        self.relu = nn.ReLU() # introduces non-linearity to the model\n",
    "        self.dropout = nn.Dropout(dropout_prob) # applied for regularization\n",
    "        self.classification_layer = nn.Linear(hidden_size, num_classes) # projects the hidden_size down to the number of target classes\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids = None, attention_mask = None):\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask)\n",
    "\n",
    "        pooler_output = outputs.pooler_output\n",
    "        hidden = self.pooler_layer(pooler_output)\n",
    "        hidden = self.relu(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        classification = self.classification_layer(hidden) # logits for each class\n",
    "\n",
    "        return classification, hidden ###STEVEN - ONLY CHANGE I MADE TO THE MODEL\n",
    "\n",
    "    def unfreeze_bert_layers(self, n_layers):\n",
    "        \"\"\"Unfreezes the top n layers of the BERT model.\"\"\"\n",
    "        layers_to_unfreeze = list(self.model.encoder.layer[-n_layers:])\n",
    "        for layer in layers_to_unfreeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da40ac41-2025-477a-9657-a4d54db5976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, checkpoint_path):\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eae8ed5d-c1e5-4842-845b-1cc0655c1290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CHECKPOINT_FOLDER = \"./checkpoints\"\n",
    "MODEL_NAME_FOLDER = \"./model_findings\"\n",
    "\n",
    "esteban_model = MulticlassClassification(\n",
    "    checkpoint=MODEL_CHECKPOINT,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    freeze_bert=False,\n",
    "    )\n",
    "\n",
    "CHECKPOINT_FILE = r\"../data/s3/fusion_data/models/bio_clinical_bert__balanced__unfrozen_layers__best.pt\"\n",
    "\n",
    "esteban_model.load_state_dict(torch.load(CHECKPOINT_FILE, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb8ca80a-a29a-4c74-b4af-b501cf1bd83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MulticlassClassification(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pooler_layer): Linear(in_features=768, out_features=201, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classification_layer): Linear(in_features=201, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esteban_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151f749e-5437-4a3f-bcac-6dd2cc3c6eb8",
   "metadata": {},
   "source": [
    "## Notes Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23f07a6c-0b30-4542-8e22-0668967471da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final embeddings layer (5 embeddings for 5 classes)\n",
    "def get_biobert_embeddings(text):\n",
    "    # Inputs:\n",
    "    #   text -> Input text (str)\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   classifications -> Final Biobert classifications = (1,num_classifcations)\n",
    "    #   hidden_embeddings -> Last hidden layer in Biobert model with vector dimensionality = (1,hidder_layer_size)\n",
    "  \n",
    "    # %% EXAMPLE OF USE\n",
    "    # classifications, hidden_embeddings = get_biobert_embeddings(text)\n",
    "    model = esteban_model\n",
    "\n",
    "    tokens_pt = biobert_tokenizer(text, return_tensors='pt',  add_special_tokens=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH, truncation=True) # (input_ids, attention_mask, token_type_ids)\n",
    "    outputs, hidden_outputs = model(**tokens_pt)\n",
    "    embeddings = outputs.detach().numpy()\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a547ea6f-e431-4ee8-b208-34facb7696e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous embeddings layer (size 201)\n",
    "def get_biobert_hidden_embeddings(text):\n",
    "    # Inputs:\n",
    "    #   text -> Input text (str)\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   hidden_embeddings -> Last hidden layer in Biobert model with vector dimensionality = (1,hidder_layer_size)\n",
    "  \n",
    "    # %% EXAMPLE OF USE\n",
    "    # classifications, hidden_embeddings = get_biobert_embeddings(text)\n",
    "    model = esteban_model\n",
    "    \n",
    "    tokens_pt = biobert_tokenizer(text, return_tensors='pt',  add_special_tokens=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH, truncation=True) # (input_ids, attention_mask, token_type_ids)\n",
    "    outputs, hidden_outputs = model(**tokens_pt)\n",
    "    hidden_embeddings = hidden_outputs.detach().numpy()\n",
    "\n",
    "    return hidden_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f2b36b05-5075-4610-9ecf-b7a38a3b2b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final embeddings layer converted to classification softmax probabilities\n",
    "def get_biobert_classifications(text):\n",
    "    # Inputs:\n",
    "    #   text -> Input text (str)\n",
    "    #\n",
    "    # Outputs:\n",
    "    #   hidden_embeddings -> Last hidden layer in Biobert model with vector dimensionality = (1,hidder_layer_size)\n",
    "  \n",
    "    # %% EXAMPLE OF USE\n",
    "    # classifications, hidden_embeddings = get_biobert_embeddings(text)\n",
    "    model = esteban_model\n",
    "    \n",
    "    tokens_pt = biobert_tokenizer(text, return_tensors='pt',  add_special_tokens=True, padding='max_length', max_length=MAX_SEQUENCE_LENGTH, truncation=True) # (input_ids, attention_mask, token_type_ids)\n",
    "    outputs, hidden_outputs = model(**tokens_pt)\n",
    "    prob = torch.softmax(outputs, dim=1) #translate to softmax probabilities\n",
    "    classifications = prob.detach().numpy()\n",
    "\n",
    "    return classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff597939-799b-4acc-a439-c5603eb7ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run on EC2 instance\n",
    "notes_train_df['notes_classifications'] = notes_train_df.history_of_present_illness.apply(get_biobert_classifications)\n",
    "notes_train_df['notes_embeddings'] = notes_train_df.history_of_present_illness.apply(get_biobert_embeddings)\n",
    "notes_train_df['notes_hidden_embeddings'] = notes_train_df.history_of_present_illness.apply(get_biobert_hidden_embeddings)\n",
    "\n",
    "notes_val_df['notes_classifications'] = notes_val_df.history_of_present_illness.apply(get_biobert_classifications)\n",
    "notes_val_df['notes_embeddings'] = notes_val_df.history_of_present_illness.apply(get_biobert_embeddings)\n",
    "notes_val_df['notes_hidden_embeddings'] = notes_val_df.history_of_present_illness.apply(get_biobert_hidden_embeddings)\n",
    "\n",
    "notes_test_df['notes_classifications'] = notes_test_df.history_of_present_illness.apply(get_biobert_classifications)\n",
    "notes_test_df['notes_embeddings'] = notes_test_df.history_of_present_illness.apply(get_biobert_embeddings)\n",
    "notes_test_df['notes_hidden_embeddings'] = notes_test_df.history_of_present_illness.apply(get_biobert_hidden_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a88774bc-f68c-42b0-996d-8696a1a49c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2086, 9)\n",
      "(1924, 9)\n",
      "(1920, 9)\n"
     ]
    }
   ],
   "source": [
    "print(notes_train_df.shape)\n",
    "print(notes_val_df.shape)\n",
    "print(notes_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7894632-9682-40e9-acfe-3e03f8a3b47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save embeddings and classifications file\n",
    "#notes_train_df.to_csv(\"../data/s3/fusion_data/notes_train_embeddings.csv\")\n",
    "#notes_val_df.to_csv(\"../data/s3/fusion_data/notes_val_embeddings.csv\")\n",
    "#notes_test_df.to_csv(\"../data/s3/fusion_data/notes_test_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ecbe16f-1ae1-47ac-984d-6c575f1fa8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_train_df.to_pickle(\"../data/s3/fusion_data/notes_train_embeddings.pkl\")\n",
    "notes_val_df.to_pickle(\"../data/s3/fusion_data/notes_val_embeddings.pkl\")\n",
    "notes_test_df.to_pickle(\"../data/s3/fusion_data/notes_test_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a34d7e-e465-4a87-be50-a2ce226108b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Image Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f8516ac2-5f3b-46fb-a715-bf9923523673",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Cinthya's model\n",
    "cinthya_model = torch.load(r\"../data/s3/fusion_data/models/EfficientNet-B3-Unb_20240331.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb65dc4c-b884-4178-b8ca-5a9713103c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2d(3, 40, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNormAct2d(\n",
       "    40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(40, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pw): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(576, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=816, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(816, 136, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          136, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(136, 816, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(816, 816, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=816, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(816, 34, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(34, 816, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(816, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1392, 1392, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1392, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1392, 232, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          232, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(232, 1392, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(1392, 1392, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1392, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1392, 58, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(58, 1392, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1392, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNormAct2d(\n",
       "          2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv_dw): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
       "        (bn2): BatchNormAct2d(\n",
       "          2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(2304, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(96, 2304, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (gate): Sigmoid()\n",
       "        )\n",
       "        (conv_pwl): Conv2d(2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNormAct2d(\n",
       "          384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "          (drop): Identity()\n",
       "          (act): Identity()\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNormAct2d(\n",
       "    1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
       "    (drop): Identity()\n",
       "    (act): SiLU(inplace=True)\n",
       "  )\n",
       "  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
       "  (classifier): Linear(in_features=1536, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cinthya_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed0c2175-edcc-4a57-8507-9823b05f3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MedicalImageDataset(Dataset):\n",
    "    def __init__(self, data, root_dir, transform=None):\n",
    "        self.annotations = data\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_id = self.annotations.iloc[index, 1]\n",
    "        img_path = os.path.join(self.root_dir, str(img_id))\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {img_path} not used in this dataset.\")\n",
    "            return None\n",
    "        #print(f\"File {img_path} found.\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return img_id, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "020cf69c-cf51-454f-8ec4-f6f0d5ed6671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based off of cinthya's definition of pulling data\n",
    "def get_chest_xray_embeddings(model, data, root_dir):\n",
    "\n",
    "    #convert img files into DataLoader Cinthya's model is expecting\n",
    "    loader_transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    \n",
    "    dataset = MedicalImageDataset(data=data,\n",
    "                                        root_dir=root_dir,\n",
    "                                        transform=loader_transform)\n",
    "    dataset = [data for data in dataset if data is not None]\n",
    "    \n",
    "    dataset_loader = DataLoader(dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    all_ids = []\n",
    "    all_probs = []\n",
    "    all_embeddings = []\n",
    "    all_densefeatures = []\n",
    "    with torch.no_grad():\n",
    "        for data in dataset_loader:\n",
    "            if data is None:  # Skip the loop iteration if the dataset returned None\n",
    "                continue\n",
    "            img_ids, images = data  \n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "\n",
    "            #for final embeddings and probabilities\n",
    "            outputs = model(images)\n",
    "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "            final_embeddings = outputs.cpu().numpy()\n",
    "            all_probs.extend(probabilities)\n",
    "            all_embeddings.extend(final_embeddings)\n",
    "            all_ids.extend(list(img_ids))  # Make sure img_ids is iterable\n",
    "\n",
    "            #for hidden embeddings (one layer up)\n",
    "            feats = model.forward_features(images)\n",
    "            feats = F.relu(feats, inplace=True)\n",
    "            feats = F.adaptive_avg_pool2d(feats, (1, 1))\n",
    "            densefeatures = feats.cpu().detach().numpy()\n",
    "            all_densefeatures.extend(densefeatures)\n",
    "            \n",
    "    return all_ids, all_probs, all_embeddings, all_densefeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8c68f2ea-d884-4211-9c2b-7ba3c584a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, train_classifications, train_embeddings, train_densefeatures = get_chest_xray_embeddings(cinthya_model, img_train_df, root_dir=r\"../data/s3/fusion_data/train_4_bal_s\")\n",
    "val_ids, val_classifications, val_embeddings, val_densefeatures = get_chest_xray_embeddings(cinthya_model, img_val_df, root_dir=r\"../data/s3/fusion_data/val_4_unb_s\")\n",
    "test_ids, test_classifications, test_embeddings, test_densefeatures = get_chest_xray_embeddings(cinthya_model, img_test_df, root_dir=r\"../data/s3/fusion_data/test_4_unb_s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b38d5cb9-b07d-4e93-b965-e792efd12117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training image embeddings dataset is size (2086, 6)\n",
      "Validation image embeddings dataset is size (1924, 6)\n",
      "Test image embeddings dataset is size (1924, 6)\n"
     ]
    }
   ],
   "source": [
    "#append embeddings to training, validation, and test datasets\n",
    "\n",
    "#train\n",
    "img_train_embeddings = pd.DataFrame()\n",
    "img_train_embeddings['dicom_id'] = train_ids\n",
    "img_train_embeddings['img_classifications'] = train_classifications\n",
    "img_train_embeddings['img_embeddings'] = train_embeddings\n",
    "img_train_embeddings['img_densefeatures'] = train_densefeatures\n",
    "img_train_embeddings['img_densefeatures'] = img_train_embeddings['img_densefeatures'].apply(np.ravel)\n",
    "img_train_df = pd.merge(img_train_df, img_train_embeddings, on='dicom_id', how='left')\n",
    "print(f\"Training image embeddings dataset is size {img_train_df.shape}\")\n",
    "\n",
    "#validation\n",
    "img_val_embeddings = pd.DataFrame()\n",
    "img_val_embeddings['dicom_id'] = val_ids\n",
    "img_val_embeddings['img_classifications'] = val_classifications\n",
    "img_val_embeddings['img_embeddings'] = val_embeddings\n",
    "img_val_embeddings['img_densefeatures'] = val_densefeatures\n",
    "img_val_embeddings['img_densefeatures'] = img_val_embeddings['img_densefeatures'].apply(np.ravel)\n",
    "img_val_df = pd.merge(img_val_df, img_val_embeddings, on='dicom_id', how='left')\n",
    "img_val_df.shape\n",
    "print(f\"Validation image embeddings dataset is size {img_val_df.shape}\")\n",
    "\n",
    "#test\n",
    "img_test_embeddings = pd.DataFrame()\n",
    "img_test_embeddings['dicom_id'] = test_ids\n",
    "img_test_embeddings['img_classifications'] = test_classifications\n",
    "img_test_embeddings['img_embeddings'] = test_embeddings\n",
    "img_test_embeddings['img_densefeatures'] = test_densefeatures\n",
    "img_test_embeddings['img_densefeatures'] = img_test_embeddings['img_densefeatures'].apply(np.ravel)\n",
    "img_test_df = pd.merge(img_test_df, img_test_embeddings, on='dicom_id', how='left')\n",
    "img_test_df.shape\n",
    "print(f\"Test image embeddings dataset is size {img_test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1017b2bf-af33-4026-a143-595611eb6dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save img_embedding files on S3\n",
    "#img_train_df.to_csv(\"../data/s3/fusion_data/img_train_embeddings.csv\")\n",
    "#img_val_df.to_csv(\"../data/s3/fusion_data/img_val_embeddings.csv\")\n",
    "#img_test_df.to_csv(\"../data/s3/fusion_data/img_test_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "838d62a8-4ed8-4349-b135-ab78e74ca475",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pickle files\n",
    "img_train_df.to_pickle(\"../data/s3/fusion_data/img_train_embeddings.pkl\")\n",
    "img_val_df.to_pickle(\"../data/s3/fusion_data/img_val_embeddings.pkl\")\n",
    "img_test_df.to_pickle(\"../data/s3/fusion_data/img_test_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65096003-a045-41c3-b671-31a9e4d0c512",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Generate Tabular Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11a6fc00-d789-44e8-b990-921daa4d821a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.0, colsample_bynode=0.0,\n",
       "              colsample_bytree=0.25, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.0, gpu_id=None, grow_policy=None, importance_type=&#x27;gain&#x27;,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=0.0, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=320, n_jobs=-1, num_class=5, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=0.0, colsample_bynode=0.0,\n",
       "              colsample_bytree=0.25, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.0, gpu_id=None, grow_policy=None, importance_type=&#x27;gain&#x27;,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=0.0, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=320, n_jobs=-1, num_class=5, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=0.0, colsample_bynode=0.0,\n",
       "              colsample_bytree=0.25, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=0.0, gpu_id=None, grow_policy=None, importance_type='gain',\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=0.0, max_depth=1, max_leaves=None,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=320, n_jobs=-1, num_class=5, ...)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unpack Adam's tabular model\n",
    "# load\n",
    "adam_model = pickle.load(open(r\"../data/s3/fusion_data/models/xgb_tabular_model_4-1-24.pkl\", \"rb\"))\n",
    "adam_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c747d057-e152-45d3-b00f-b546a8b4d554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pain</th>\n",
       "      <th>acuity</th>\n",
       "      <th>finding_names</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11388716</td>\n",
       "      <td>98.8</td>\n",
       "      <td>106.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11539363</td>\n",
       "      <td>99.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10833304</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19849119</td>\n",
       "      <td>98.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11749991</td>\n",
       "      <td>100.6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  temperature  heartrate  resprate  o2sat    sbp    dbp  pain  \\\n",
       "0    11388716         98.8      106.0      22.0   96.0   93.0   67.0     0   \n",
       "1    11539363         99.1       80.0      16.0   97.0  162.0   67.0     0   \n",
       "2    10833304         97.0       98.0      14.0  100.0  159.0   88.0     2   \n",
       "3    19849119         98.6       92.0      20.0   98.0  127.0   70.0     0   \n",
       "4    11749991        100.6      110.0      16.0   97.0  166.0  100.0     8   \n",
       "\n",
       "   acuity finding_names  target  \n",
       "0     2.0   atelectasis       1  \n",
       "1     3.0   atelectasis       1  \n",
       "2     2.0   atelectasis       1  \n",
       "3     2.0   atelectasis       1  \n",
       "4     2.0   atelectasis       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cbba48e-7652-4d4e-a439-11ad564d4ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2086, 11)\n",
      "(1924, 11)\n",
      "(1920, 11)\n"
     ]
    }
   ],
   "source": [
    "#rename findings to indexed conditions\n",
    "conditions = [\n",
    "    (tabular_train_df['finding_names'] == 'no_findings'),\n",
    "    (tabular_train_df['finding_names'] == 'atelectasis'),\n",
    "    (tabular_train_df['finding_names'] == 'cardiomegaly'),\n",
    "    (tabular_train_df['finding_names'] == 'lung_opacity'),\n",
    "    (tabular_train_df['finding_names'] == 'pleural_effusion')\n",
    "]\n",
    "choices = [0, 1, 2, 3, 4]\n",
    "tabular_train_df['target'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "#val\n",
    "conditions = [\n",
    "    (tabular_val_df['finding_names'] == 'no_findings'),\n",
    "    (tabular_val_df['finding_names'] == 'atelectasis'),\n",
    "    (tabular_val_df['finding_names'] == 'cardiomegaly'),\n",
    "    (tabular_val_df['finding_names'] == 'lung_opacity'),\n",
    "    (tabular_val_df['finding_names'] == 'pleural_effusion')\n",
    "]\n",
    "choices = [0, 1, 2, 3, 4]\n",
    "tabular_val_df['target'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "#test\n",
    "conditions = [\n",
    "    (tabular_test_df['finding_names'] == 'no_findings'),\n",
    "    (tabular_test_df['finding_names'] == 'atelectasis'),\n",
    "    (tabular_test_df['finding_names'] == 'cardiomegaly'),\n",
    "    (tabular_test_df['finding_names'] == 'lung_opacity'),\n",
    "    (tabular_test_df['finding_names'] == 'pleural_effusion')\n",
    "]\n",
    "choices = [0, 1, 2, 3, 4]\n",
    "tabular_test_df['target'] = np.select(conditions, choices, default=0)\n",
    "\n",
    "print(tabular_train_df.shape)\n",
    "print(tabular_val_df.shape)\n",
    "print(tabular_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04bfa0fa-e077-4abb-afd4-0651f95a00ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns for X and y\n",
    "X_columns = ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity']\n",
    "y_columns = ['target']  # as per team agreement\n",
    "\n",
    "tabular_train_df.set_index('patient_id', inplace=True)\n",
    "tabular_val_df.set_index('patient_id', inplace=True)\n",
    "tabular_test_df.set_index('patient_id', inplace=True)\n",
    "\n",
    "\n",
    "# Split for 4_bal_s\n",
    "X_train = tabular_train_df[X_columns]\n",
    "y_train = tabular_train_df[y_columns]\n",
    "X_val   = tabular_val_df[X_columns]     # intentionally the same as X_val_6_unb_m\n",
    "y_val   = tabular_val_df[y_columns]     # intentionally the same as unb\n",
    "X_test  = tabular_test_df[X_columns]    # intentionally the same as unb\n",
    "y_test  = tabular_test_df[y_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c97488fd-a134-4868-b5a0-976a9064fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adam's data preprocessing\n",
    "# Define data type columns\n",
    "ordinal_cols = ['pain', 'acuity']\n",
    "ratio_cols   = ['temperature', 'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp']\n",
    "\n",
    "# Preprocess parameters\n",
    "impOrd   = SimpleImputer(strategy='constant', fill_value=-1)\n",
    "impRatio = SimpleImputer(strategy='mean')\n",
    "scale    = RobustScaler(with_centering=False)\n",
    "encode   = OrdinalEncoder()\n",
    "\n",
    "# Simple imputing Preprocess\n",
    "ord_pp_steps  = Pipeline([('missing',impOrd),('Ordinal',encode),('Scale',scale)])\n",
    "ratio_pp_steps= Pipeline([('mean',impRatio),('Scale',scale)])\n",
    "\n",
    "# create the preprocessor stage of final pipeline\n",
    "t=[(\"ordinal\",ord_pp_steps,ordinal_cols),('ratio',ratio_pp_steps ,ratio_cols)]\n",
    "preprocessor = ColumnTransformer(transformers = t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dec96bd-b2ea-40b1-8e37-5e9df233c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update pipeline\n",
    "u_pipe = Pipeline([('preprocess',preprocessor), ('estimator', adam_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8eb0064-eea3-4866-9c7a-1d18a4cd52db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tabular embeddings\n",
    "#because xgboost is a collection of trees, will just take classifications from xgboost for embeddings\n",
    "#Adam's code for pulling probabilities\n",
    "\n",
    "def get_tabular_embeddings(X_data, y_data, model):\n",
    "    # Fit the training data\n",
    "    u_pipe.fit(X_data, y_data)\n",
    "\n",
    "    # Predict probabilities for training data\n",
    "    probs = u_pipe.predict_proba(X_data)\n",
    "    \n",
    "    # Convert the predicted probabilities to a DataFrame, using the same index as X_train\n",
    "    probs_df = pd.DataFrame(probs, columns=[f'tabular_classifications{i}' for i in range(len(np.unique(y_data)))], index=X_data.index)\n",
    "    probs_df = probs_df.reset_index()\n",
    "    \n",
    "    return probs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6729275b-1460-41df-bc09-458ca67889f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get classifications\n",
    "tabular_train_probs = get_tabular_embeddings(X_train, y_train, adam_model)\n",
    "tabular_val_probs = get_tabular_embeddings(X_val, y_val, adam_model)\n",
    "tabular_test_probs = get_tabular_embeddings(X_test, y_test, adam_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25d9ce38-c55b-4760-a7c5-145e6e4d91d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with tabular_dfs\n",
    "tabular_train_df = pd.merge(tabular_train_df, tabular_train_probs, on='patient_id', how='left')\n",
    "tabular_val_df = pd.merge(tabular_val_df, tabular_val_probs, on='patient_id', how='left')\n",
    "tabular_test_df = pd.merge(tabular_test_df, tabular_test_probs, on='patient_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ba3b68ea-f239-457b-be2c-5ae7558009ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pickle files\n",
    "tabular_train_df.to_pickle(\"../data/s3/fusion_data/tab_train_embeddings.pkl\")\n",
    "tabular_val_df.to_pickle(\"../data/s3/fusion_data/tab_val_embeddings.pkl\")\n",
    "tabular_test_df.to_pickle(\"../data/s3/fusion_data/tab_test_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47bb5f3-e983-4a9e-9508-c990acc13db9",
   "metadata": {},
   "source": [
    "# Concatenate Embeddings together and save output file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d429ab29-e74b-4b0a-b612-39d2ba87103c",
   "metadata": {},
   "source": [
    "We have pulled:\n",
    "\n",
    "- Softmax classifications for notes and images from individual models\n",
    "- Final embeddings (without the softmax function applied) for individual models\n",
    "- The embedding layers beneath the final embeddings for individual models\n",
    "\n",
    "To try for fusion:\n",
    "- classification alone (Adam is tackling this)\n",
    "- final embedding layers alone (should perform similarly to the first example)\n",
    "- hidden embedding layers alone (focus 1)\n",
    "- final embedding + hidden embedding layers (focus 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e09f9bd-d073-4e2c-ac57-4791d8d34918",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download from pickle files\n",
    "notes_train_embeddings = pd.read_pickle(\"../data/s3/fusion_data/notes_train_embeddings.pkl\")\n",
    "notes_val_embeddings = pd.read_pickle(\"../data/s3/fusion_data/notes_val_embeddings.pkl\")\n",
    "notes_test_embeddings = pd.read_pickle(\"../data/s3/fusion_data/notes_test_embeddings.pkl\")\n",
    "\n",
    "img_train_embeddings = pd.read_pickle(\"../data/s3/fusion_data/img_train_embeddings.pkl\")\n",
    "img_val_embeddings = pd.read_pickle(\"../data/s3/fusion_data/img_val_embeddings.pkl\")\n",
    "img_test_embeddings = pd.read_pickle(\"../data/s3/fusion_data/img_test_embeddings.pkl\")\n",
    "\n",
    "tab_train_embeddings = pd.read_pickle(\"../data/s3/fusion_data/tab_train_embeddings.pkl\")\n",
    "tab_val_embeddings = pd.read_pickle(\"../data/s3/fusion_data/tab_val_embeddings.pkl\")\n",
    "tab_test_embeddings = pd.read_pickle(\"../data/s3/fusion_data/tab_test_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5640ab4c-2e90-46de-a3fe-c72c0800f9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['patient_id', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
       "       'dbp', 'pain', 'acuity', 'finding_names', 'target',\n",
       "       'tabular_classifications0', 'tabular_classifications1',\n",
       "       'tabular_classifications2', 'tabular_classifications3',\n",
       "       'tabular_classifications4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab_train_embeddings.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c021ef86-8729-4614-b688-4504800cbe38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge everything into one file\n",
    "combined_train_df = pd.merge(combined_train_df, notes_train_embeddings[['patient_id', 'notes_classifications', 'notes_embeddings', 'notes_hidden_embeddings']],on='patient_id', how='left')\n",
    "combined_train_df = pd.merge(combined_train_df, img_train_embeddings[['patient_id', 'img_classifications', 'img_embeddings', 'img_densefeatures']],on='patient_id', how='left')\n",
    "combined_train_df = pd.merge(combined_train_df, tab_train_embeddings[['patient_id', \n",
    "                                                                      'tabular_classifications0', 'tabular_classifications1',\n",
    "                                                                      'tabular_classifications2', 'tabular_classifications3',\n",
    "                                                                      'tabular_classifications4']],on='patient_id', how='left')\n",
    "\n",
    "combined_val_df = pd.merge(combined_val_df, notes_val_embeddings[['patient_id', 'notes_classifications', 'notes_embeddings', 'notes_hidden_embeddings']],on='patient_id', how='left')\n",
    "combined_val_df = pd.merge(combined_val_df, img_val_embeddings[['patient_id', 'img_classifications', 'img_embeddings', 'img_densefeatures']],on='patient_id', how='left')\n",
    "combined_val_df = pd.merge(combined_val_df, tab_val_embeddings[['patient_id', \n",
    "                                                                'tabular_classifications0', 'tabular_classifications1',\n",
    "                                                                'tabular_classifications2', 'tabular_classifications3',\n",
    "                                                                'tabular_classifications4']],on='patient_id', how='left')\n",
    "\n",
    "combined_test_df = pd.merge(combined_test_df, notes_test_embeddings[['patient_id', 'notes_classifications', 'notes_embeddings', 'notes_hidden_embeddings']],on='patient_id', how='left')\n",
    "combined_test_df = pd.merge(combined_test_df, img_test_embeddings[['patient_id', 'img_classifications', 'img_embeddings', 'img_densefeatures']],on='patient_id', how='left')\n",
    "combined_test_df = pd.merge(combined_test_df, tab_test_embeddings[['patient_id', \n",
    "                                                                   'tabular_classifications0', 'tabular_classifications1',\n",
    "                                                                   'tabular_classifications2', 'tabular_classifications3',\n",
    "                                                                   'tabular_classifications4']],on='patient_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dfa34de-df33-4855-be78-25ebcec47120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2086, 38)\n",
      "(1924, 38)\n",
      "(1920, 38)\n"
     ]
    }
   ],
   "source": [
    "print(combined_train_df.shape)\n",
    "print(combined_val_df.shape)\n",
    "print(combined_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cff9a08-6c0f-4fb8-b837-37523fe3f119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as pickle files\n",
    "combined_train_df.to_pickle(\"../data/s3/fusion_data/combined_train_df_all_embeddings.pkl\")\n",
    "combined_val_df.to_pickle(\"../data/s3/fusion_data/combined_val_df_all_embeddings.pkl\")\n",
    "combined_test_df.to_pickle(\"../data/s3/fusion_data/combined_test_df_all_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23273cbb-fcb3-4a86-a4b5-974100634a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unravel classifications for steven\n",
    "#function to unravel (de-nest) and split apart any pandas value containing a np.array\n",
    "def reshape_data(data):\n",
    "    #gets rid of nested embeddings\n",
    "    flattened_data = pd.DataFrame()\n",
    "    \n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].apply(np.ravel)\n",
    "\n",
    "        col_names = []\n",
    "        for i in range(data[col][0].shape[0]):\n",
    "            col_name = col + str(i)\n",
    "            col_names.append(col_name)\n",
    "\n",
    "        flattened_data[col_names] = pd.DataFrame(data[col].tolist(), index= data.index)\n",
    "    \n",
    "    return flattened_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ff38d9d-eb77-4fa3-acd8-6ba9daac6efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull out just classifcations\n",
    "train_classes_img_notes = combined_train_df[['patient_id', 'notes_classifications', 'img_classifications']]\n",
    "val_classes_img_notes = combined_val_df[['patient_id', 'notes_classifications', 'img_classifications']]\n",
    "test_classes_img_notes = combined_test_df[['patient_id', 'notes_classifications', 'img_classifications']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d3fb430-27d4-452e-b9ff-81f0a09d1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make each classification its own column\n",
    "train_classes_img_notes = reshape_data(train_classes_img_notes)\n",
    "val_classes_img_notes = reshape_data(val_classes_img_notes)\n",
    "test_classes_img_notes = reshape_data(test_classes_img_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb38efc0-30f0-4b0f-b28e-58893fb2f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename paitent_id0 to patient_id\n",
    "train_classes_img_notes = train_classes_img_notes.rename(columns={\"patient_id0\": \"patient_id\"})\n",
    "val_classes_img_notes = val_classes_img_notes.rename(columns={\"patient_id0\": \"patient_id\"})\n",
    "test_classes_img_notes = test_classes_img_notes.rename(columns={\"patient_id0\": \"patient_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3c83626-8fbb-404c-b64e-5b23d19ef3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join with combine dfs\n",
    "combined_train_df = pd.merge(combined_train_df, train_classes_img_notes,on='patient_id', how='left')\n",
    "combined_val_df = pd.merge(combined_val_df, val_classes_img_notes,on='patient_id', how='left')\n",
    "combined_test_df = pd.merge(combined_test_df, test_classes_img_notes,on='patient_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93d1b909-2c36-4309-8f10-3013100c9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as pickle files for steven\n",
    "combined_train_df.to_pickle(\"../data/s3/fusion_data/combined_train_df_all_embeddings_classifications.pkl\")\n",
    "combined_val_df.to_pickle(\"../data/s3/fusion_data/combined_val_df_all_embeddings_classifications.pkl\")\n",
    "combined_test_df.to_pickle(\"../data/s3/fusion_data/combined_test_df_all_embeddings_classifications.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p310)",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

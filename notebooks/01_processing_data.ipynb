{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ed62287-84b4-4970-a2ee-e496683499e2",
   "metadata": {},
   "source": [
    "# Processing data for fusion models\n",
    "Purpose: to access processed data and combine for tabular, notes, and images\n",
    "\n",
    "### Dataset selection: 4 findings, single label, balanced**\n",
    "\n",
    "**for now because smaller dataset/testing pipeline, perhaps switch to unbalanced and for imaging data, will perform augmentation to class balance\n",
    "\n",
    "TODOs:\n",
    "- Save final dataframes for people to reference patient IDs being used (TONIGHT)\n",
    "- Convert local access to EC2/S3 access so this notebook can be run by anyone (and can be accessed no problem in a pipeline (TOMORROW)\n",
    "- Change data types to 4 finds, single label, unbalanced? and just balance the imaging data alone? (RUN BOTH TONIGHT)\n",
    "- For now leave balanced but test unbalanced vs balanced in the fusion context\n",
    "- potentially use this notebook to generate the image generator (dig further into the image embeddings code)\n",
    "\n",
    "This will be for early concatenation and early fusion models\n",
    "\n",
    "Currently accessing locally --> convert to EC2 and S3 access ASAP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "931fd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, KFold\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.multioutput import MultiOutputClassifier, ClassifierChain, MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "rand_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c47b2d-3d19-468d-912c-3b1c91d97f34",
   "metadata": {},
   "source": [
    "# Notes and Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29777526-1a21-482a-b339-6b1c59602084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#notes data - currently pulling locally from google drive (need to mount to S3 and pull from there to use EC2 in the future for larger models!)\n",
    "data_dir_processed = r\"C:/Users/Carolyn/Documents/MIDS/210 Capstone/train_validation_test__datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85330b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data files... C:/Users/Carolyn/Documents/MIDS/210 Capstone/fusion_data\\test_set__chexpert__4_findings__single_label__unbalanced.json test\n",
      "Loading data files... C:/Users/Carolyn/Documents/MIDS/210 Capstone/fusion_data\\train_set__chexpert__4_findings__single_label__balanced.json train\n",
      "Loading data files... C:/Users/Carolyn/Documents/MIDS/210 Capstone/fusion_data\\validation_set__chexpert__4_findings__single_label__unbalanced.json validate\n",
      "Total Cols\n",
      " Index(['patient_id', 'visit_id', 'study_id', 'temperature', 'heartrate',\n",
      "       'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity',\n",
      "       'positive_label_total', 'finding_names', 'radiology_note',\n",
      "       'discharge_note', 'chief_complaint',\n",
      "       'major_surgical_or_invasive_procedure', 'history_of_present_illness',\n",
      "       'past_medical_history', 'family_history', 'atelectasis', 'cardiomegaly',\n",
      "       'lung_opacity', 'pleural_effusion', 'dataset_type'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Define the names of the JSON files\n",
    "#train_df_filename = \"/train_set__chexpert__4_findings__single_label__unbalanced.json\"\n",
    "#test_df_filename = \"/test_set__chexpert__4_findings__single_label__unbalanced.json\"\n",
    "#valid_df_filename = \"/validation_set__chexpert__4_findings__single_label__unbalanced.json\"\n",
    "\n",
    "#train_balanced_df_filename = \"/train_set__chexpert__4_findings__single_label__balanced.json\"\n",
    "\n",
    "def load_and_combine_json_files(directory_path, search_pattern):\n",
    "    # Use glob to find JSON files in the directory based on the search pattern\n",
    "    pop_files = glob(directory_path + search_pattern)\n",
    "\n",
    "    # Initialize an empty DataFrame to hold all the data\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each JSON file\n",
    "    for file in pop_files:\n",
    "        # Determine the dataset type based on the file name\n",
    "        if 'train' in file:\n",
    "            dataset_type = 'train'\n",
    "        elif 'test' in file:\n",
    "            dataset_type = 'test'\n",
    "        elif 'val' in file:\n",
    "            dataset_type = 'validate'\n",
    "        else:\n",
    "            dataset_type = 'unknown'\n",
    "\n",
    "        print('Loading data files...', file, dataset_type)\n",
    "        # Load the JSON file into a DataFrame\n",
    "        with open(file) as f:\n",
    "            data = json.load(f)\n",
    "        df = pd.DataFrame(data)\n",
    "        if dataset_type == 'train':\n",
    "            train_df = df\n",
    "        elif dataset_type == 'test':\n",
    "            test_df = df\n",
    "        elif dataset_type == 'validate':\n",
    "            val_df = df\n",
    "        else:\n",
    "            print(\"Unknown dataset type!\")\n",
    "\n",
    "        # Add a new column to flag the dataset type\n",
    "        df['dataset_type'] = dataset_type\n",
    "\n",
    "        # Append the DataFrame to the combined DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    return train_df, test_df, val_df, combined_df\n",
    "\n",
    "# Define parameters for the function to combine JSON files\n",
    "directory_path = 'C:/Users/Carolyn/Documents/MIDS/210 Capstone/fusion_data/'\n",
    "pop_files = '*.json'  # This pattern can be changed based on the files you're looking for\n",
    "\n",
    "# Load and combine the JSON files\n",
    "train_df, test_df, val_df, combined_df = load_and_combine_json_files(directory_path, pop_files)\n",
    "\n",
    "print('Total Cols\\n',train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "974d4f1c-13f3-45d4-beb1-57d725257710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>resprate</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>sbp</th>\n",
       "      <th>dbp</th>\n",
       "      <th>pain</th>\n",
       "      <th>acuity</th>\n",
       "      <th>positive_label_total</th>\n",
       "      <th>finding_names</th>\n",
       "      <th>radiology_note</th>\n",
       "      <th>discharge_note</th>\n",
       "      <th>chief_complaint</th>\n",
       "      <th>major_surgical_or_invasive_procedure</th>\n",
       "      <th>history_of_present_illness</th>\n",
       "      <th>past_medical_history</th>\n",
       "      <th>family_history</th>\n",
       "      <th>atelectasis</th>\n",
       "      <th>cardiomegaly</th>\n",
       "      <th>lung_opacity</th>\n",
       "      <th>pleural_effusion</th>\n",
       "      <th>dataset_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>11388716.0</td>\n",
       "      <td>23706855</td>\n",
       "      <td>51255419.0</td>\n",
       "      <td>98.8</td>\n",
       "      <td>106.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___               Unit No:   ___\\n \\...</td>\n",
       "      <td>SOB</td>\n",
       "      <td>None</td>\n",
       "      <td>___ with history of DVT on warfarin, silent MI...</td>\n",
       "      <td>ONCOLOGIC HISTORY: \\n- Early ___: presented to...</td>\n",
       "      <td>Mother had an MI in her ___.  Father had an MI...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>11539363.0</td>\n",
       "      <td>23558226</td>\n",
       "      <td>55922046.0</td>\n",
       "      <td>99.1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___                  Unit No:   ___\\...</td>\n",
       "      <td>Chest pain</td>\n",
       "      <td>___ Cardiac Catheterization by Dr. ___</td>\n",
       "      <td>Mr ___ is a ___ yo M w/IDDM, HTN, HLD, has not...</td>\n",
       "      <td>- IDDM  \\n - HTN  \\n - HLD</td>\n",
       "      <td>Noncontributory</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>10833304.0</td>\n",
       "      <td>26184887</td>\n",
       "      <td>59599449.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___          Unit No:   ___\\n \\nAdmi...</td>\n",
       "      <td>Lip swelling, shortness of breath</td>\n",
       "      <td>None</td>\n",
       "      <td>This is a ___ F PMhx hypothyroidism, depressio...</td>\n",
       "      <td>- HTN\\n- Hypothyroidism\\n- Urticaria, chronic ...</td>\n",
       "      <td>Estranged from family, no known history of mal...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>19849119.0</td>\n",
       "      <td>27397159</td>\n",
       "      <td>58419216.0</td>\n",
       "      <td>98.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___                   Unit No:   ___...</td>\n",
       "      <td>Confusion</td>\n",
       "      <td>None</td>\n",
       "      <td>___ PMHx Hep C Cirrhosis, HTN, DM II presents ...</td>\n",
       "      <td>PMH: DMII, Cirrhosis, grade 1 esophageal varic...</td>\n",
       "      <td>Brothers x3 both with MI's. Father ___ arthrit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>11749991.0</td>\n",
       "      <td>20503367</td>\n",
       "      <td>55801381.0</td>\n",
       "      <td>100.6</td>\n",
       "      <td>110.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>atelectasis</td>\n",
       "      <td>FINAL REPORT\\...</td>\n",
       "      <td>\\nName:  ___                    Unit No:   __...</td>\n",
       "      <td>N/V, Abdominal Pain</td>\n",
       "      <td>None</td>\n",
       "      <td>___ with hx of COPD, CHF, esophageal ulcer, an...</td>\n",
       "      <td>- HTN\\n- CVA\\n- CHF\\n- Restles leg\\n- Fibromya...</td>\n",
       "      <td>Not obtained</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  visit_id    study_id  temperature  heartrate  resprate  \\\n",
       "992   11388716.0  23706855  51255419.0         98.8      106.0      22.0   \n",
       "1099  11539363.0  23558226  55922046.0         99.1       80.0      16.0   \n",
       "569   10833304.0  26184887  59599449.0         97.0       98.0      14.0   \n",
       "7640  19849119.0  27397159  58419216.0         98.6       92.0      20.0   \n",
       "1255  11749991.0  20503367  55801381.0        100.6      110.0      16.0   \n",
       "\n",
       "      o2sat    sbp    dbp  pain  acuity  positive_label_total finding_names  \\\n",
       "992    96.0   93.0   67.0     0     2.0                   1.0   atelectasis   \n",
       "1099   97.0  162.0   67.0     0     3.0                   1.0   atelectasis   \n",
       "569   100.0  159.0   88.0     2     2.0                   1.0   atelectasis   \n",
       "7640   98.0  127.0   70.0     0     2.0                   1.0   atelectasis   \n",
       "1255   97.0  166.0  100.0     8     2.0                   1.0   atelectasis   \n",
       "\n",
       "                                         radiology_note  \\\n",
       "992                                    FINAL REPORT\\...   \n",
       "1099                                   FINAL REPORT\\...   \n",
       "569                                    FINAL REPORT\\...   \n",
       "7640                                   FINAL REPORT\\...   \n",
       "1255                                   FINAL REPORT\\...   \n",
       "\n",
       "                                         discharge_note  \\\n",
       "992    \\nName:  ___               Unit No:   ___\\n \\...   \n",
       "1099   \\nName:  ___                  Unit No:   ___\\...   \n",
       "569    \\nName:  ___          Unit No:   ___\\n \\nAdmi...   \n",
       "7640   \\nName:  ___                   Unit No:   ___...   \n",
       "1255   \\nName:  ___                    Unit No:   __...   \n",
       "\n",
       "                        chief_complaint  \\\n",
       "992                                 SOB   \n",
       "1099                         Chest pain   \n",
       "569   Lip swelling, shortness of breath   \n",
       "7640                          Confusion   \n",
       "1255                N/V, Abdominal Pain   \n",
       "\n",
       "        major_surgical_or_invasive_procedure  \\\n",
       "992                                     None   \n",
       "1099  ___ Cardiac Catheterization by Dr. ___   \n",
       "569                                     None   \n",
       "7640                                    None   \n",
       "1255                                    None   \n",
       "\n",
       "                             history_of_present_illness  \\\n",
       "992   ___ with history of DVT on warfarin, silent MI...   \n",
       "1099  Mr ___ is a ___ yo M w/IDDM, HTN, HLD, has not...   \n",
       "569   This is a ___ F PMhx hypothyroidism, depressio...   \n",
       "7640  ___ PMHx Hep C Cirrhosis, HTN, DM II presents ...   \n",
       "1255  ___ with hx of COPD, CHF, esophageal ulcer, an...   \n",
       "\n",
       "                                   past_medical_history  \\\n",
       "992   ONCOLOGIC HISTORY: \\n- Early ___: presented to...   \n",
       "1099                         - IDDM  \\n - HTN  \\n - HLD   \n",
       "569   - HTN\\n- Hypothyroidism\\n- Urticaria, chronic ...   \n",
       "7640  PMH: DMII, Cirrhosis, grade 1 esophageal varic...   \n",
       "1255  - HTN\\n- CVA\\n- CHF\\n- Restles leg\\n- Fibromya...   \n",
       "\n",
       "                                         family_history  atelectasis  \\\n",
       "992   Mother had an MI in her ___.  Father had an MI...          1.0   \n",
       "1099                                    Noncontributory          1.0   \n",
       "569   Estranged from family, no known history of mal...          1.0   \n",
       "7640  Brothers x3 both with MI's. Father ___ arthrit...          1.0   \n",
       "1255                                       Not obtained          1.0   \n",
       "\n",
       "      cardiomegaly  lung_opacity  pleural_effusion dataset_type  \n",
       "992            0.0           0.0               0.0        train  \n",
       "1099           0.0           0.0               0.0        train  \n",
       "569            0.0           0.0               0.0        train  \n",
       "7640           0.0           0.0               0.0        train  \n",
       "1255           0.0           0.0               0.0        train  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1739c6cd-e841-4356-a96d-99c37c9efc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_column_values_sum_and_percentage(dataframe_input, column_input):\n",
    "    total_sum = dataframe_input[column_input].sum()\n",
    "    percentages = dataframe_input[column_input] / total_sum\n",
    "    sums_percentages = pd.DataFrame({\n",
    "        'sum': dataframe_input[column_input],\n",
    "        'percentage': percentages\n",
    "    })\n",
    "    sums_percentages['cumsum_percentage'] = sums_percentages['percentage'].cumsum()\n",
    "    sums_percentages['sum'] = sums_percentages['sum'].apply(lambda x: \"{:,}\".format(x))\n",
    "    sums_percentages['percentage'] = sums_percentages['percentage'].mul(100).round(1).astype(str) + '%'\n",
    "    sums_percentages['cumsum_percentage'] = sums_percentages['cumsum_percentage'].mul(100).round(1).astype(str) + '%'\n",
    "    return sums_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0930a15a-5f1d-4c97-912f-8e3b8944a251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>percentage</th>\n",
       "      <th>cumsum_percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finding_names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no_finding</th>\n",
       "      <td>706</td>\n",
       "      <td>33.3%</td>\n",
       "      <td>33.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atelectasis</th>\n",
       "      <td>353</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>50.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiomegaly</th>\n",
       "      <td>353</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>66.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_opacity</th>\n",
       "      <td>353</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>83.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pleural_effusion</th>\n",
       "      <td>353</td>\n",
       "      <td>16.7%</td>\n",
       "      <td>100.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sum percentage cumsum_percentage\n",
       "finding_names                                     \n",
       "no_finding        706      33.3%             33.3%\n",
       "atelectasis       353      16.7%             50.0%\n",
       "cardiomegaly      353      16.7%             66.7%\n",
       "lung_opacity      353      16.7%             83.3%\n",
       "pleural_effusion  353      16.7%            100.0%"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_column_values_sum_and_percentage(train_df.groupby(\"finding_names\").agg({\"study_id\": \"count\"}).sort_values(\"study_id\", ascending=False), \"study_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34211348-2382-4a8d-9d18-bb1309bb873a",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaa5bbb-b00c-4030-8e1a-801e43f80837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image directories\n",
    "local_base_dir = 'C:/Users/Carolyn/Documents/MIDS/210 Capstone'\n",
    "latest_processed_file = 'Processed_Image_Data_March_11_2024.csv'\n",
    "latest_file_path = os.path.join(local_base_dir, latest_processed_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd562f5-0441-4cd5-bca5-2357c9696a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16877 entries, 0 to 16876\n",
      "Data columns (total 40 columns):\n",
      " #   Column                                      Non-Null Count  Dtype  \n",
      "---  ------                                      --------------  -----  \n",
      " 0   patient_id                                  16877 non-null  int64  \n",
      " 1   study_id                                    16877 non-null  int64  \n",
      " 2   atelectasis                                 16877 non-null  float64\n",
      " 3   cardiomegaly                                16877 non-null  float64\n",
      " 4   edema                                       16877 non-null  float64\n",
      " 5   lung_opacity                                16877 non-null  float64\n",
      " 6   pleural_effusion                            16877 non-null  float64\n",
      " 7   pneumonia                                   16877 non-null  float64\n",
      " 8   prev_data_type                              16877 non-null  object \n",
      " 9   prev_is_sample                              16877 non-null  bool   \n",
      " 10  dicom_id                                    16877 non-null  object \n",
      " 11  PerformedProcedureStepDescription           16817 non-null  object \n",
      " 12  ViewPosition                                16877 non-null  object \n",
      " 13  Rows                                        16877 non-null  int64  \n",
      " 14  Columns                                     16877 non-null  int64  \n",
      " 15  StudyDate                                   16877 non-null  int64  \n",
      " 16  StudyTime                                   16877 non-null  float64\n",
      " 17  ProcedureCodeSequence_CodeMeaning           16877 non-null  object \n",
      " 18  ViewCodeSequence_CodeMeaning                16877 non-null  object \n",
      " 19  PatientOrientationCodeSequence_CodeMeaning  16520 non-null  object \n",
      " 20  jpg_filename                                16877 non-null  object \n",
      " 21  anomaly                                     16877 non-null  int64  \n",
      " 22  no_findings                                 16877 non-null  bool   \n",
      " 23  set                                         16877 non-null  int64  \n",
      " 24  train_6_unb_m                               16877 non-null  int64  \n",
      " 25  test_6_unb_m                                16877 non-null  int64  \n",
      " 26  val_6_unb_m                                 16877 non-null  int64  \n",
      " 27  train_6_bal_m                               16877 non-null  int64  \n",
      " 28  train_6_unb_s                               16877 non-null  int64  \n",
      " 29  test_6_unb_s                                16877 non-null  int64  \n",
      " 30  val_6_unb_s                                 16877 non-null  int64  \n",
      " 31  train_6_bal_s                               16877 non-null  int64  \n",
      " 32  train_4_unb_m                               16877 non-null  int64  \n",
      " 33  test_4_unb_m                                16877 non-null  int64  \n",
      " 34  val_4_unb_m                                 16877 non-null  int64  \n",
      " 35  train_4_bal_m                               16877 non-null  int64  \n",
      " 36  train_4_unb_s                               16877 non-null  int64  \n",
      " 37  test_4_unb_s                                16877 non-null  int64  \n",
      " 38  val_4_unb_s                                 16877 non-null  int64  \n",
      " 39  train_4_bal_s                               16877 non-null  int64  \n",
      "dtypes: bool(2), float64(7), int64(23), object(8)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a dataframe\n",
    "image_loc_df = pd.read_csv(latest_file_path)\n",
    "\n",
    "train_img_loc_df = image_loc_df[image_loc_df.train_4_bal_s == 1]\n",
    "val_img_loc_df = image_loc_df[image_loc_df.val_4_unb_s == 1]\n",
    "test_img_loc_df = image_loc_df[image_loc_df.test_4_unb_s == 1]\n",
    "\n",
    "image_loc_df.info()\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b9c530-32fc-4d26-b9b8-2d5aaa29709f",
   "metadata": {},
   "source": [
    "# Combine Files together for final dataset for fusion models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b8987e-32ce-4412-96cd-1a5e183024fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert patient ids in tab/notes df to int\n",
    "train_df.patient_id = train_df.patient_id.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0b812f-56ea-4c3b-b950-621d1f9d4677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create combined train, validation, and test datasets from note/tabular and imaging data of sizes: \n",
      "(2086, 27)\n",
      "(1924, 27)\n",
      "(1920, 27)\n",
      "Null values for image IDs in combined_train_df: 0\n",
      "Null values for image IDs in combined_train_df: 0\n",
      "Null values for image IDs in combined_train_df: 0\n"
     ]
    }
   ],
   "source": [
    "#join based on patient id and remove NA values\n",
    "combined_train_df = pd.merge(train_df,train_img_loc_df[['patient_id', 'dicom_id']],on='patient_id', how='left').dropna().reset_index()\n",
    "combined_val_df = pd.merge(val_df,val_img_loc_df[['patient_id','dicom_id']],on='patient_id', how='left').dropna().reset_index()\n",
    "combined_test_df = pd.merge(test_df,test_img_loc_df[['patient_id', 'dicom_id']],on='patient_id', how='left').dropna().reset_index()\n",
    "\n",
    "print(\"Create combined train, validation, and test datasets from note/tabular and imaging data of sizes: \")\n",
    "print(combined_train_df.shape)\n",
    "print(combined_val_df.shape)\n",
    "print(combined_test_df.shape)\n",
    "\n",
    "print(\"Null values for image IDs in combined_train_df:\", sum(combined_train_df.dicom_id.isna()))\n",
    "print(\"Null values for image IDs in combined_train_df:\", sum(combined_val_df.dicom_id.isna()))\n",
    "print(\"Null values for image IDs in combined_train_df:\", sum(combined_test_df.dicom_id.isna()))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c210cfc2-b163-4b90-b5ee-f9d58badbb49",
   "metadata": {},
   "source": [
    "# Use DICOM_ID to identify images for appended early fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e111a85-94fa-45e9-9f1b-063cb08192d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO use dicom_id to pull image values into array for early fusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc3651d-a6be-4eb1-bdbd-a2c515e8615a",
   "metadata": {},
   "source": [
    "# Separate files for late fusion approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd04e97-d5fb-476b-a6ef-06a464199cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'patient_id', 'visit_id', 'study_id', 'temperature',\n",
       "       'heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity',\n",
       "       'positive_label_total', 'finding_names', 'radiology_note',\n",
       "       'discharge_note', 'chief_complaint',\n",
       "       'major_surgical_or_invasive_procedure', 'history_of_present_illness',\n",
       "       'past_medical_history', 'family_history', 'atelectasis', 'cardiomegaly',\n",
       "       'lung_opacity', 'pleural_effusion', 'dataset_type', 'dicom_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Combined dataset has columns: {combined_train_df.columns}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc96f6e5-c730-473c-9f05-226a9327f0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['atelectasis', 'cardiomegaly', 'lung_opacity', 'pleural_effusion',\n",
       "       'no_finding'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Combined dataset has the following findings (true labels): {combined_train_df.finding_names.unique()}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "739b72f6-fe6e-499c-b2b2-3b97afba022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split combined data into images, notes, and tabular datasets\n",
      "Imaging data has columns Index(['patient_id', 'dicom_id', 'finding_names'], dtype='object')\n",
      "Notes data has columns Index(['patient_id', 'chief_complaint', 'history_of_present_illness',\n",
      "       'past_medical_history', 'family_history', 'finding_names'],\n",
      "      dtype='object')\n",
      "Tabular data has columns Index(['patient_id', 'temperature', 'heartrate', 'resprate', 'o2sat', 'sbp',\n",
      "       'dbp', 'pain', 'acuity', 'finding_names'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "## separate out fusion_df into tabular, images, and notes alone\n",
    "\n",
    "#tabular data alone\n",
    "tabular_train_df = combined_train_df[['patient_id', 'temperature','heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity', 'finding_names']]\n",
    "tabular_val_df = combined_val_df[['patient_id', 'temperature','heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity', 'finding_names']]\n",
    "tabular_test_df = combined_test_df[['patient_id', 'temperature','heartrate', 'resprate', 'o2sat', 'sbp', 'dbp', 'pain', 'acuity', 'finding_names']]\n",
    "\n",
    "#notes data alone\n",
    "notes_train_df = combined_train_df[['patient_id', 'chief_complaint', 'history_of_present_illness','past_medical_history', 'family_history', 'finding_names']]\n",
    "notes_val_df = combined_val_df[['patient_id', 'chief_complaint', 'history_of_present_illness','past_medical_history', 'family_history', 'finding_names']]\n",
    "notes_test_df = combined_test_df[['patient_id', 'chief_complaint', 'history_of_present_illness','past_medical_history', 'family_history', 'finding_names']]\n",
    "\n",
    "#image data alone (only dicom_id - use for data generator at embeddings step\n",
    "img_train_df = combined_train_df[['patient_id', 'dicom_id', 'finding_names']]\n",
    "img_val_df = combined_val_df[['patient_id', 'dicom_id', 'finding_names']]\n",
    "img_test_df = combined_test_df[['patient_id', 'dicom_id', 'finding_names']]\n",
    "\n",
    "print(\"Split combined data into images, notes, and tabular datasets\")\n",
    "print(f\"Imaging data has columns {img_train_df.columns}\")\n",
    "print(f\"Notes data has columns {notes_train_df.columns}\")\n",
    "print(f\"Tabular data has columns {tabular_train_df.columns}\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6b8c0e6-c7d1-4229-a397-fcdcc4573b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed notes data to have [UNK] in place of ____\n"
     ]
    }
   ],
   "source": [
    "#replace ___ with [UNK] for all notes data\n",
    "notes_train_df.loc[:, \"history_of_present_illness\"] = notes_train_df[\"history_of_present_illness\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_val_df.loc[:, \"history_of_present_illness\"] = notes_val_df[\"history_of_present_illness\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_test_df.loc[:, \"history_of_present_illness\"] = notes_test_df[\"history_of_present_illness\"].str.replace(\"___\", \"[UNK]\")\n",
    "\n",
    "notes_train_df.loc[:, \"chief_complaint\"] = notes_train_df[\"chief_complaint\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_val_df.loc[:, \"chief_complaint\"] = notes_val_df[\"chief_complaint\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_test_df.loc[:, \"chief_complaint\"] = notes_test_df[\"chief_complaint\"].str.replace(\"___\", \"[UNK]\")\n",
    "\n",
    "notes_train_df.loc[:, \"past_medical_history\"] = notes_train_df[\"past_medical_history\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_val_df.loc[:, \"past_medical_history\"] = notes_val_df[\"past_medical_history\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_test_df.loc[:, \"past_medical_history\"] = notes_test_df[\"past_medical_history\"].str.replace(\"___\", \"[UNK]\")\n",
    "\n",
    "notes_train_df.loc[:, \"family_history\"] = notes_train_df[\"family_history\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_val_df.loc[:, \"family_history\"] = notes_val_df[\"family_history\"].str.replace(\"___\", \"[UNK]\")\n",
    "notes_test_df.loc[:, \"family_history\"] = notes_test_df[\"family_history\"].str.replace(\"___\", \"[UNK]\")\n",
    "\n",
    "print(\"Processed all notes data to have [UNK] in place of ____\")\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "999e50b9-59af-4be5-a677-d5a23f60b071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Created file img_train_df with size: (2086, 3)\n",
      "Created file img_val_df with size: (1924, 3)\n",
      "Created file img_test_df with size: (1920, 3)\n",
      "Created file notes_train_df with size: (2086, 6)\n",
      "Created file notes_val_df with size: (1924, 6)\n",
      "Created file notes_test_df with size: (1920, 6)\n",
      "Created file tabular_train_df with size: (2086, 10)\n",
      "Created file tabular_val_df with size: (1924, 10)\n",
      "Created file tabular_test_df with size: (1920, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Created file img_train_df with size: {img_train_df.shape}\")\n",
    "print(f\"Created file img_val_df with size: {img_val_df.shape}\")\n",
    "print(f\"Created file img_test_df with size: {img_test_df.shape}\")\n",
    "\n",
    "print(f\"Created file notes_train_df with size: {notes_train_df.shape}\")\n",
    "print(f\"Created file notes_val_df with size: {notes_val_df.shape}\")\n",
    "print(f\"Created file notes_test_df with size: {notes_test_df.shape}\")\n",
    "\n",
    "print(f\"Created file tabular_train_df with size: {tabular_train_df.shape}\")\n",
    "print(f\"Created file tabular_val_df with size: {tabular_val_df.shape}\")\n",
    "print(f\"Created file tabular_test_df with size: {tabular_test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22be00e-43ad-4bfb-927d-18342319387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: save output df as files for others to use as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

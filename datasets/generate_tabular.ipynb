{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "181c2d9a",
   "metadata": {},
   "source": [
    "## 1. \n",
    "## 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78c53a66-728f-4586-be9c-eb72f32d49eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "# from tensordict import TensorDict\n",
    "\n",
    "pd.set_option('display.max_info_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37d3686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ad44078-6649-433c-89f0-1e83f250a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"/Users/leegary/Downloads/mimic_iv_multilabel__json_files__20240302/train_set__chexpert.json\"\n",
    ") as f:\n",
    "    data = json.load(f)\n",
    "    np.asarray(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d934a8e",
   "metadata": {},
   "source": [
    "How Many "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c0217d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data['acuity'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7960e18e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7293d0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9630 entries, 0 to 9629\n",
      "Data columns (total 26 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   patient_id                            9630 non-null   float64\n",
      " 1   visit_id                              9630 non-null   int64  \n",
      " 2   study_id                              9630 non-null   float64\n",
      " 3   temperature                           9630 non-null   float64\n",
      " 4   heartrate                             9630 non-null   float64\n",
      " 5   resprate                              9630 non-null   float64\n",
      " 6   o2sat                                 9630 non-null   float64\n",
      " 7   sbp                                   9630 non-null   float64\n",
      " 8   dbp                                   9630 non-null   float64\n",
      " 9   pain                                  9630 non-null   int64  \n",
      " 10  acuity                                9630 non-null   float64\n",
      " 11  pathologies_number                    9630 non-null   float64\n",
      " 12  pathologies_names                     9630 non-null   object \n",
      " 13  radiology_note                        9630 non-null   object \n",
      " 14  discharge_note                        9630 non-null   object \n",
      " 15  chief_complaint                       9630 non-null   object \n",
      " 16  major_surgical_or_invasive_procedure  9630 non-null   object \n",
      " 17  history_of_present_illness            9630 non-null   object \n",
      " 18  past_medical_history                  9630 non-null   object \n",
      " 19  family_history                        9630 non-null   object \n",
      " 20  atelectasis                           9630 non-null   float64\n",
      " 21  cardiomegaly                          9630 non-null   float64\n",
      " 22  edema                                 9630 non-null   float64\n",
      " 23  lung_opacity                          9630 non-null   float64\n",
      " 24  pleural_effusion                      9630 non-null   float64\n",
      " 25  pneumonia                             9630 non-null   float64\n",
      "dtypes: float64(16), int64(2), object(8)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2e0a7b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9630"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data['patient_id'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7949019",
   "metadata": {},
   "source": [
    "\n",
    "1. Import scikit-learn... Download most recent data from Esteban\n",
    "\n",
    "2. Combine test, train, val  (identify them with 2 cols [test/train/val] split) - 16,907 (train 11)\n",
    "\n",
    "\n",
    "    Full Set\n",
    "    ```\n",
    "    0      test         2817   16.661738\n",
    "    1     train        11272   66.670610\n",
    "    2  validate         2818   16.667652\n",
    "    ```\n",
    "    Sample Set\n",
    "    ```\n",
    "    data_type  is_sample  count\n",
    "    1      test       True    282\n",
    "    3     train       True   1127\n",
    "    5  validate       True    282\n",
    "    ```\n",
    "\n",
    "3.  Combine sample sets patient IDs (test, train, val)\n",
    "    - Change acuity to int64 and remove all unneeded data\n",
    "    - Keep columns 0, 3 - 10, 20-25 and remove everything else except the target variables\n",
    "    - Index the resulting file by patientID \n",
    "    - Split all to x features and y labels\n",
    "\n",
    "4. create a pipeline in scikit-learn to predict a multi classification outcome target variable with softmax probabilities \n",
    "    - Confirm whether any values are missing\n",
    "    - Scale features \n",
    "    - Decide datatypes (Ordinal, Ratio)\n",
    "    - Use XGBoost for robustness (this will be for early fusion)\n",
    "\n",
    "5. Hyperparameter tuning using validation set\n",
    "    - Use log loss \n",
    "    -  Gridsearch \n",
    "\n",
    "6. Prediction testing and scoring metrics (precision, recall, f1 score, and auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88912b7a-7436-4c1e-ba27-c63c6b028601",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = [\n",
    "    \"patient_id\",\n",
    "    \"visit_id\",\n",
    "    \"study_id\",\n",
    "    \"temperature\",\n",
    "    \"heartrate\",\n",
    "    \"resprate\",\n",
    "    \"o2sat\",\n",
    "    \"sbp\",\n",
    "    \"dbp\",\n",
    "]\n",
    "output_cols = [\n",
    "    \"atelectasis\",\n",
    "    \"cardiomegaly\",\n",
    "    \"edema\",\n",
    "    \"lung_opacity\",\n",
    "    \"pleural_effusion\",\n",
    "    \"pneumonia\",\n",
    "]\n",
    "input_df = pd.DataFrame(\n",
    "    data=data,\n",
    "    columns=input_cols,\n",
    ")\n",
    "output_df = pd.DataFrame(data=data, columns=output_cols)\n",
    "input_df = input_df.astype(\n",
    "    {\n",
    "        \"patient_id\": int,\n",
    "        \"study_id\": int,\n",
    "    }\n",
    ")\n",
    "output_df = output_df.astype(\n",
    "    {\n",
    "        \"atelectasis\": int,\n",
    "        \"cardiomegaly\": int,\n",
    "        \"edema\": int,\n",
    "        \"lung_opacity\": int,\n",
    "        \"pleural_effusion\": int,\n",
    "        \"pneumonia\": int,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642e92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe692b-1095-4093-b1ad-bb370d8d9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_min_max(df, col_name):\n",
    "    xmin = df[col_name].min()\n",
    "    xmax = df[col_name].max()\n",
    "    df[col_name] = (df[col_name] - xmin) / (xmax - xmin)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db296fb9-7ddf-4370-88e9-7f690ad1c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = scale_min_max(input_df, \"temperature\")\n",
    "input_df = scale_min_max(input_df, \"heartrate\")\n",
    "input_df = scale_min_max(input_df, \"resprate\")\n",
    "input_df = scale_min_max(input_df, \"sbp\")\n",
    "input_df = scale_min_max(input_df, \"dbp\")\n",
    "input_df[\"o2sat\"] = input_df[\"o2sat\"] * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e2c867-aea7-4373-bf23-9e1e917f7297",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor(input_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32f1f80-4ebf-4040-b294-64d6e7d24f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tensor = torch.tensor(output_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d0962-8eee-424a-b57a-2711accd0dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TensorDataset(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aad285a-6f2a-4e9b-88f0-daeef2bafc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9efee-74d5-4fa2-9fc7-68f85f1b4c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f52864-6ccb-443d-9b19-6b69f03b11ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f12bff7-5724-488c-b8d5-6c74ddd51b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc6ffa-d95d-481d-b335-f0c3cb71e466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tabular_df(path):\n",
    "    \"\"\"\n",
    "    Generates the tabular dataframes\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    index_cols = [\"patient_id\", \"visit_id\", \"study_id\"]\n",
    "    input_cols = [\n",
    "        \"patient_id\",\n",
    "        \"visit_id\",\n",
    "        \"study_id\",\n",
    "        \"temperature\",\n",
    "        \"heartrate\",\n",
    "        \"resprate\",\n",
    "        \"o2sat\",\n",
    "        \"sbp\",\n",
    "        \"dbp\",\n",
    "    ]\n",
    "    output_cols = [\n",
    "        \"atelectasis\",\n",
    "        \"cardiomegaly\",\n",
    "        \"edema\",\n",
    "        \"lung_opacity\",\n",
    "        \"pleural_effusion\",\n",
    "        \"pneumonia\",\n",
    "    ]\n",
    "    input_df = pd.DataFrame(\n",
    "        data=data,\n",
    "        columns=input_cols,\n",
    "    )\n",
    "    output_df = pd.DataFrame(data=data, columns=output_cols)\n",
    "    input_df = input_df.astype(\n",
    "        {\n",
    "            \"patient_id\": int,\n",
    "            \"study_id\": int,\n",
    "        }\n",
    "    )\n",
    "    output_df = output_df.astype(\n",
    "        {\n",
    "            \"atelectasis\": int,\n",
    "            \"cardiomegaly\": int,\n",
    "            \"edema\": int,\n",
    "            \"lung_opacity\": int,\n",
    "            \"pleural_effusion\": int,\n",
    "            \"pneumonia\": int,\n",
    "        }\n",
    "    )\n",
    "    return [input_df, output_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba71247-9b66-485d-9ba1-e7260c6fc7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tabular(path, name, all_inputs):\n",
    "    \"\"\"\n",
    "    Generates the tabular tensor files for loading.\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    input_cols = [\n",
    "        \"patient_id\",\n",
    "        \"visit_id\",\n",
    "        \"study_id\",\n",
    "        \"temperature\",\n",
    "        \"heartrate\",\n",
    "        \"resprate\",\n",
    "        \"o2sat\",\n",
    "        \"sbp\",\n",
    "        \"dbp\",\n",
    "        \"atelectasis\",\n",
    "        \"cardiomegaly\",\n",
    "        \"edema\",\n",
    "        \"lung_opacity\",\n",
    "        \"pleural_effusion\",\n",
    "        \"pneumonia\",\n",
    "    ]\n",
    "    input_df = pd.DataFrame(\n",
    "        data=data,\n",
    "        columns=input_cols,\n",
    "    )\n",
    "    input_df = input_df.astype(\n",
    "        {\n",
    "            \"patient_id\": int,\n",
    "            \"study_id\": int,\n",
    "            \"atelectasis\": int,\n",
    "            \"cardiomegaly\": int,\n",
    "            \"edema\": int,\n",
    "            \"lung_opacity\": int,\n",
    "            \"pleural_effusion\": int,\n",
    "            \"pneumonia\": int,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    def scale_min_max(df, col_name):\n",
    "        xmin = all_inputs[col_name].min()\n",
    "        xmax = all_inputs[col_name].max()\n",
    "        df[col_name] = (df[col_name] - xmin) / (xmax - xmin)\n",
    "        return df\n",
    "\n",
    "    # normalize\n",
    "    input_df = scale_min_max(input_df, \"temperature\")\n",
    "    input_df = scale_min_max(input_df, \"heartrate\")\n",
    "    input_df = scale_min_max(input_df, \"resprate\")\n",
    "    input_df = scale_min_max(input_df, \"sbp\")\n",
    "    input_df = scale_min_max(input_df, \"dbp\")\n",
    "    input_df[\"o2sat\"] = input_df[\"o2sat\"] * 0.01\n",
    "\n",
    "    input_df.to_csv(\"../data/s3/\" + name, index=False)\n",
    "    print(\"generated \" + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc6528-16df-4ee5-87d4-e0da34c0bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/Users/leegary/Downloads/mimic_iv_multilabel__json_files__20240302/\"\n",
    "paths = [\n",
    "    [\"tabular_test.csv\", \"test_set__chexpert.json\"],\n",
    "    [\"tabular_train.csv\", \"train_set__chexpert.json\"],\n",
    "    [\"tabular_valid.csv\", \"validation_set__chexpert.json\"],\n",
    "]\n",
    "inputs = []\n",
    "outputs = []\n",
    "for [name, path] in paths:\n",
    "    [input_df, output_df] = get_tabular_df(root + path)\n",
    "    inputs.append(input_df)\n",
    "\n",
    "all_inputs = pd.concat(inputs, axis=0)\n",
    "\n",
    "for [name, path] in paths:\n",
    "    generate_tabular(root + path, name, all_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fc015-077e-4a74-b064-96d252859cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(input_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a9febc-c400-4669-ad40-8835a2385f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(output_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e18613-5f1d-4d7e-9ed0-4bd850dd06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt(\"../data/s3/tensors/tabular_label_names.txt\", delimiter=\",\", dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e079f8-be56-47fc-9823-400e9cbf3e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import SimpleNamespace\n",
    "\n",
    "import mimic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e62732-d995-402d-9ad4-b3a7c7d7b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_test = '{\"data_mode\": \"tabular_numpy_train\", \"batch_size\": 32}'\n",
    "x = json.loads(config_test, object_hook=lambda d: SimpleNamespace(**d))\n",
    "dataloaders = mimic.MimicDataLoader(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15701924-1e6d-46b8-bbc2-e4f28b944bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloaders.train_loader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
